<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer and Information Ethics (Stanford Encyclopedia of Philosophy)</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta name="citation_title" content="Computer and Information Ethics" />
<meta name="citation_author" content="Bynum, Terrell" />
<meta name="citation_publication_date" content="2001/08/14" />
<meta name="DC.title" content="Computer and Information Ethics" />
<meta name="DC.creator" content="Bynum, Terrell" />
<meta name="DCTERMS.issued" scheme="DCTERMS.W3CDTF" content="2001-08-14" />
<meta name="DCTERMS.modified" scheme="DCTERMS.W3CDTF" content="2008-10-23" />
<link rel="alternate" type="application/rss+xml" title="Stanford Encyclopedia of Philosophy" href="http://plato.stanford.edu/rss/sep.xml" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/sepentry.css" />
<link rel="stylesheet" type="text/css" media="print, handheld" href="../../css/sepprint.css" />

</head>

<body>

<div id="pagetopleft" onclick="location.href='../../'">&nbsp;</div>

<div id="navmenu">
  <div class="menuheading"><a href="../../search/searcher.py" class="menulink">Search the SEP</a></div>
<form method="get" action="../../search/searcher.py">
    <div style="padding: 0px 0px 2px 5px"><input size="18" name="query" style="width: 140px; background-color: #eeeeee; color: #444444" /></div>
    <div class="menuitem">&bull; <a href="../../search/searcher.py" class="menulink">Advanced Search</a></div>
    <div class="menuitem">&bull; <a href="../../tools/" class="menulink">Tools</a> &bull; <a href="http://plato.stanford.edu/rss/sep.xml" class="menulink" target="other">RSS Feed</a></div>
</form>

<hr />

<div class="menuheading"><a href="../../contents.html" class="menulink">Table of Contents</a></div>

<div class="menuitem">&bull; <a href="../../new.html" class="menulink">What's New</a></div>

<div class="menuitem">&bull; <a href="../../archives/" class="menulink">Archives</a></div>

<div class="menuitem">&bull; <a href="../../projected-contents.html" class="menulink">Projected Contents</a></div>

<hr />

<div class="menuheading"><a href="../../info.html" class="menulink">Editorial Information</a></div>

<div class="menuitem">&bull; <a href="../../about.html" class="menulink">About the SEP</a></div>

<div class="menuitem">&bull; <a href="../../board.html" class="menulink">Editorial Board</a></div>

<div class="menuitem">&bull; <a href="../../cite.html" class="menulink">How to Cite the SEP</a></div>

<div class="menuitem">&bull; <a href="../../special-characters.html" class="menulink">Special Characters</a></div>

<hr />

<div class="menuheading"><a href="../../support/" class="menulink">Support the SEP</a></div>

<div class="menuitem">&bull; <a href="../../support/friends.html" class="menulink">PDFs for SEP Friends</a></div>

<div class="menuitem">&bull; <a href="../../support/donate.html" class="menulink">Make a Donation</a></div>

<div class="menuitem">&bull; <a href="../../support/sepia.html" class="menulink">SEPIA for Libraries</a></div>

<hr />

<div class="menuheading"><a href="m&#97;ilto:webmaster&#37;40plato&#37;2estanford&#37;2eedu" class="menulink">Contact the SEP</a></div>

<hr />

<div class="copyright">
<a href="http://plato.stanford.edu/"><img src="../../symbols/sepman.png" height="50" align="left" alt="SEP logo" border="0" /></a>
<a href="../../info.html#c">&copy;</a>
<a href="http://mally.stanford.edu/" target="other">Metaphysics Research Lab</a>,
<a href="http://www-csli.stanford.edu/" target="other">CSLI</a>,
<a href="http://www.stanford.edu/" target="other">Stanford University</a>
</div>


</div><!-- end #navmenu -->

<div id="pagetopright">
  <a href="../../" class="menulink"><img src="../../symbols/septop.jpg" alt="Stanford Encyclopedia of Philosophy" /></a>
</div>



<div id="content"> 

<!--FUNDING MESSAGE-->
<div id="message">
The SEP is freely available to all U.K. higher and further educational institutions because of financial support from the JISC.
</div>

<!--FUNDING MESSAGE-->

<!--ACADEMIC LINKS-->
<div id="linklist">
<a href="http://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=ethics-computer" target="other">Author &amp; Citation Info</a> | 
<a href="https://leibniz.stanford.edu/friends/preview/ethics-computer/" target="other">Friends PDF Preview</a> |
<a href="https://inpho.cogs.indiana.edu/entity?sep=ethics-computer&amp;redirect=True" target="other">InPho Search</a> |
<a href="http://philpapers.org/sep/ethics-computer/" target="other">PhilPapers Bibliography</a> 
</div>
<!--ACADEMIC LINKS-->

<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Computer and Information Ethics</h1><div id="pubinfo"><em>First published Tue Aug 14, 2001; substantive revision Thu Oct 23, 2008</em></div>

<p>

In most countries of the world, the &ldquo;information
revolution&rdquo; has altered many aspects of life significantly:
commerce, employment, medicine, security, transportation,
entertainment, and so on. Consequently, information and communication
technology (ICT) has affected &mdash; in both good ways and bad ways
&mdash; community life, family life, human relationships, education,
careers, freedom, and democracy (to name just a few
examples). &ldquo;Computer and information ethics&rdquo;, in the
broadest sense of this phrase, can be understood as that branch of
applied ethics which studies and analyzes such social and ethical
impacts of ICT. The present essay concerns this broad new field of
applied ethics.</p>

<p>

The more specific term &ldquo;computer ethics&rdquo; has been used to
refer to applications by professional philosophers of traditional
Western theories like utilitarianism, Kantianism, or virtue ethics, to
ethical cases that significantly involve computers and computer
networks. &ldquo;Computer ethics&rdquo; also has been used to refer to
a kind of professional ethics in which computer professionals apply
codes of ethics and standards of good practice within their
profession. In addition, other more specific names, like
&ldquo;cyberethics&rdquo; and &ldquo;Internet ethics&rdquo;, have been
used to refer to aspects of computer ethics associated with the
Internet.</p>

<p>

During the past several decades, the robust and rapidly growing field
of computer and information ethics has generated new university
courses, research professorships, research centers, conferences,
workshops, professional organizations, curriculum materials, books and
journals.</p>

<!--Entry Contents-->
<ul>
<li><a href="#SomHisMil">1. Some Historical Milestones</a>
   <ul>
   <li><a href="#FouComInfEth">1.1 The Foundation of Computer and Information Ethics</a></li>
   <li><a href="#DefComEth">1.2 Defining Computer Ethics</a></li>
   </ul></li>
<li><a href="#ExaTopComEth">2. Example Topics in Computer Ethics</a>
   <ul>
   <li><a href="#ComWor">2.1 Computers in the Workplace</a></li>
   <li><a href="#ComCri">2.2 Computer Crime</a></li>
   <li><a href="#PriAno">2.3 Privacy and Anonymity</a></li>
   <li><a href="#IntPro">2.4 Intellectual Property</a></li>
   <li><a href="#ProRes">2.5 Professional Responsibility</a></li>
   <li><a href="#Glo">2.6 Globalization</a></li>
   </ul></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#AcaToo">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a>
   <ul>
   <li><a href="#PapBoo">Papers and Books</a></li>
   <li><a href="#JouWebSit">Journals and Web Sites</a></li>
   </ul></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

<h2><a name="SomHisMil">1. Some Historical Milestones</a></h2>

<h3><a name="FouComInfEth">1.1 The Foundation of Computer and Information Ethics</a></h3>

<p>

In the mid 1940s, innovative developments in science and philosophy
led to the creation of a new branch of ethics that would later be
called &ldquo;computer ethics&rdquo; or &ldquo;information
ethics&rdquo;. The founder of this new philosophical field was the
American scholar Norbert Wiener, a professor of mathematics and
engineering at MIT. During the Second World War, together with
colleagues in America and Great Britain, Wiener helped to develop
electronic computers and other new and powerful information
technologies. While engaged in this war effort, Wiener and colleagues
created a new branch of applied science that Wiener named
&ldquo;cybernetics&rdquo; (from the Greek word for the pilot of a
ship). Even while the War was raging, Wiener foresaw enormous social
and ethical implications of cybernetics combined with electronic
computers. He predicted that, after the War, the world would undergo
&ldquo;a second industrial revolution&rdquo; &mdash; an
&ldquo;automatic age&rdquo; with &ldquo;enormous potential for good
and for evil&rdquo; that would generate a staggering number of new
ethical challenges and opportunities. </p>

<p>

When the War ended, Wiener wrote the book <em>Cybernetics</em> (1948)
in which he described his new branch of applied science and identified
some social and ethical implications of electronic computers. Two
years later he published <em>The Human Use of Human Beings</em>
(1950), a book in which he explored a number of ethical issues that
computer and information technology would likely generate. The issues
that he identified in those two books, plus his later book <em>God and
Golem, Inc.</em> (1963), included topics that are still important
today: computers and security, computers and unemployment,
responsibilities of computer professionals, computers for persons with
disabilities, computers and religion, information networks and
globalization, virtual communities, teleworking, merging of human
bodies with machines, robot ethics, artificial intelligence, and a
number of other subjects. (See Bynum 2000, 2004, 2005, 2006.) </p>

<p>

Although he coined the name &ldquo;cybernetics&rdquo; for his new
science, Wiener apparently did not see himself as also creating a new
branch of ethics. As a result, he did not coin a name like
&ldquo;computer ethics&rdquo; or &ldquo;information
ethics&rdquo;. These terms came into use decades later. (See the
discussion below.) In spite of this, Wiener's three relevant books
(1948, 1950, 1963) do lay down a powerful foundation, and do use an
effective methodology, for today's field of computer and information
ethics. His thinking, however, was far ahead of other scholars; and,
at the time, many people considered him to be an eccentric scientist
who was engaging in flights of fantasy about ethics. Apparently, no
one &mdash; not even Wiener himself &mdash; recognized the profound
importance of his ethics achievements; and nearly two decades would
pass before some of the social and ethical impacts of information
technology, which Wiener had predicted in the late 1940s, would become
obvious to other scholars and to the general public. </p>

<p>

In <em>The Human Use of Human Beings</em>, Wiener explored some likely
effects of information technology upon key human values like <em>life,
health, happiness, abilities, knowledge, freedom, security, and
opportunities</em>. The metaphysical ideas and analytical methods that
he employed were so powerful and wide-ranging that they could be used
effectively for identifying, analyzing and resolving social and
ethical problems associated with all kinds of information technology,
including, for example, computers and computer networks; radio,
television and telephones; news media and journalism; even books and
libraries. Because of the breadth of Wiener's concerns and the
applicability of his ideas and methods to every kind of information
technology, the term &ldquo;information ethics&rdquo; is an apt name
for the new field of ethics that he founded. As a result, the term
&ldquo;computer ethics&rdquo;, as it is typically used today, names
only a subfield of Wiener's much broader
 concerns.<sup>[<a href="notes.html#1" name="note-1">1</a>]</sup></p>

<p>

In laying down a foundation for information ethics, Wiener developed a
cybernetic view of human nature and society, which led him to an
ethically suggestive account of the purpose of a human life. Based
upon this, he adopted &ldquo;great principles of justice&rdquo; that
he believed all societies ought to follow. These powerful ethical
concepts enabled Wiener to analyze information ethics issues of all
kinds.</p>

<h4>A cybernetic view of human nature</h4>

<p>

Wiener's cybernetic understanding of human nature stressed the
physical structure of the human body and the remarkable potential for
learning and creativity that human physiology makes possible. While
explaining human intellectual potential, he regularly compared the
human body to the physiology of less intelligent creatures like
insects:</p>


<blockquote>

<em>Cybernetics takes the view that the structure of the machine or of
the organism is an index of the performance that may be expected from
it</em>. The fact that the mechanical rigidity of the insect is such
as to limit its intelligence while the mechanical fluidity of the
human being provides for his almost indefinite intellectual expansion
is highly relevant to the point of view of this book.
&hellip;&nbsp;man's advantage over the rest of nature is that he has
the physiological and hence the intellectual equipment to adapt
himself to radical changes in his environment. The human species is
strong only insofar as it takes advantage of the innate, adaptive,
learning faculties that its physiological structure makes
possible. (Wiener 1954, pp. 57-58, italics in the original)

</blockquote>

<p>

Given the physiology of human beings, it is possible for them to take
in a wide diversity of information from the external world, access
information about conditions and events within their own bodies, and
process all that information in ways that constitute reasoning,
calculating, wondering, deliberating, deciding and many other
intellectual activities. Wiener concluded that the purpose of a human
life is to flourish as the kind of information-processing organisms
that humans naturally are:</p>

<blockquote>

I wish to show that the human individual, capable of vast learning and
study, which may occupy almost half of his life, is physically
equipped, as the ant is not, for this capacity. Variety and
possibility are inherent in the human sensorium &mdash; and are indeed
the key to man's most noble flights &mdash; because variety and
possibility belong to the very structure of the human
organism. (Wiener 1954, pp. 51-52)

</blockquote>


<h4>Underlying metaphysics</h4>

<p>

Wiener's account of human nature presupposed a metaphysical view of
the universe that considers the world and all the entities within it,
including humans, to be combinations of matter-energy and
information. Everything in the world is a mixture of both of these,
and <em>thinking</em>, according to Wiener, is actually <em>a kind of
information processing</em>. Consequently, the brain</p>

<blockquote>

does not secrete thought &ldquo;as the liver does bile&rdquo;, as the
earlier materialists claimed, nor does it put it out in the form of
energy, as the muscle puts out its activity. Information is
information, not matter or energy. No materialism which does not admit
this can survive at the present day. (Wiener 1948,
p. 155)

</blockquote>

<p>

According to Wiener's metaphysical view, everything in the universe
comes into existence, persists, and then disappears because of the
continuous mixing and mingling of information and
matter-energy. Living organisms, including human beings, are actually
patterns of information that persist through an ongoing exchange of
matter-energy. Thus, he says of human beings,</p>

<blockquote>

<p>
 We are but whirlpools in a river of ever-flowing water. We are not
stuff that abides, but patterns that perpetuate themselves. (Wiener
1954, p. 96)</p>

<p>&hellip;</p>

<p>
 The individuality of the body is that of a flame&hellip;of a form
 rather than of a bit of substance. (Wiener 1954, p. 102)</p>

</blockquote>

<p>

Using the language of today's &ldquo;information age&rdquo; we would
say that, according to Wiener, human beings are &ldquo;information
objects&rdquo;; and their intellectual capacities, as well as their
personal identities, are dependent upon persisting patterns of
information and information processing within the body, rather than on
specific bits of matter-energy.</p>


<h4>Justice and human flourishing</h4>

<p>

According to Wiener, for human beings to flourish they must be free to
engage in creative and flexible actions and thereby maximize their
full potential as intelligent, decision-making beings in charge of
their own lives. This is the purpose of a human life. Because people
have various levels of talent and possibility, however, one person's
achievements will be different from those of others. It is possible,
though, to lead a good human life &mdash; to flourish &mdash; in an
indefinitely large number of ways; for example, as a diplomat,
scientist, teacher, nurse, doctor, soldier, housewife, midwife,
musician, artist, tradesman, artisan, and so on.</p>

<p>

This understanding of the purpose of a human life led Wiener to adopt
what he called &ldquo;great principles of justice&rdquo; upon which
society should be built. He believed that adherence to those
principles by a society would maximize a person's ability to flourish
through variety and flexibility of human action. Although Wiener
stated his &ldquo;great principles&rdquo;, he did not assign names to
them. For purposes of easy reference, let us call them &ldquo;The
Principle of Freedom&rdquo;, &ldquo;The Principle of Equality&rdquo;
and &ldquo;The Principle of Benevolence&rdquo;. Using Wiener's own
words yields the following list of &ldquo;great principles&rdquo;
(1954, pp. 105-106):</p>

<blockquote>

<p>
  <strong>The Principle of Freedom</strong> <br />
 Justice requires &ldquo;the liberty of each human being to develop in
 his freedom the full measure of the human possibilities embodied in
 him.&rdquo; </p>

<p>
 <strong>The Principle of Equality</strong> <br />
 Justice requires &ldquo;the equality by which what is just for A and
 B remains just when the positions of A and B are
 interchanged.&rdquo;</p>

<p>
 <strong>The Principle of Benevolence</strong> <br /> Justice requires
 &ldquo;a good will between man and man that knows no limits short of
 those of humanity itself.&rdquo;</p>

</blockquote>

<p>

Given Wiener's cybernetic account of human nature and society, it
follows that people are fundamentally social beings, and that they can
reach their full potential only when they are part of a community of
similar beings. Society, therefore, is essential to a good human
life. <em>Despotic societies</em>, however, actually <em>stifle human
freedom</em>; and indeed they violate all three of the &ldquo;great
principles of justice&rdquo;. For this reason, Wiener explicitly
adopted a fourth principle of justice to assure that the first three
would not be violated. Let us call this additional principle
&ldquo;The Principle of Minimum Infringement of Freedom&rdquo;:</p>

<blockquote>
 <strong>The Principle of Minimum Infringement of Freedom</strong>
 What compulsion the very existence of the community and the state may
 demand must be exercised in such a way as to produce no unnecessary
 infringement of freedom (1954, p. 106).
</blockquote>


<h4>A refutation of ethical relativism</h4>

<p>

If one grants Wiener's account of a good society and of human nature,
it follows that <em>a wide diversity of cultures &mdash; with
different customs, languages, religions, values and practices &mdash;
could provide a context in which humans can flourish.</em> Sometimes
ethical relativists use the existence of different cultures as proof
that there is not &mdash; and could not be &mdash; an underlying
ethical foundation for societies all around the globe. In response to
such relativism, Wiener could argue that, given his understanding of
human nature and the purpose of a human life, we can embrace and
welcome a rich variety of cultures and practices while still
advocating adherence to &ldquo;the great principles of
justice&rdquo;. Those principles offer <em>a cross-cultural foundation
for ethics</em>, even though they leave room for immense cultural
diversity. The one restriction that Wiener would require in any
society is that it must provide a context where humans can realize
their full potential as sophisticated information-processing agents,
making decisions and choices, and thereby taking responsibility for
their own lives. Wiener believed that this is possible only where
significant freedom, equality and human compassion prevail.</p>

<h4>Methodology in information ethics</h4>

<p>

Because Wiener did not think of himself as creating a new branch of
ethics, he did not provide metaphilosophical comments about what he
was doing while analyzing an information ethics issue or
case. Instead, he plunged directly into his analyses. Consequently, if
we want to know about Wiener's method of analysis, we need to
observe <em>what he does</em>, rather than look for any
metaphilosophical commentary upon his own procedures.</p>

<p>

When observing Wiener's way of analyzing information ethics issues and
trying to resolve them, we find &mdash; for example, in <em>The Human
Use of Human Beings</em> &mdash; that he tries <em>to assimilate new
cases by applying already existing, ethically acceptable laws, rules,
and practices</em>. In any given society, there is a network of
existing practices, laws, rules and principles that govern human
behavior within that society. These &ldquo;policies&rdquo; &mdash; to
borrow a helpful word from Moor (1985) &mdash; constitute a
&ldquo;received policy cluster&rdquo; (see Bynum and Schubert 1997);
and in a reasonably just society, they can serve as <em>a good
starting point for developing an answer to any information ethics
question</em>. Wiener's methodology is to combine the &ldquo;received
policy cluster&rdquo; of one's society with his account of human
nature, plus his &ldquo;great principles of justice&rdquo;, plus
critical skills in clarifying vague or ambiguous language. In this
way, he achieved a very effective method for analyzing information
ethics issues. Borrowing from Moor's later, and very apt, description
of computer ethics methodology (Moor 1985), we can describe Wiener's
methodology as follows:</p>

<ol>
 
<li>Identify an ethical question or case regarding the integration of
information technology into society. Typically this focuses upon
technology-generated possibilities that could affect (or are already
affecting) life, health, security, happiness, freedom, knowledge,
opportunities, or other key human values.</li>

<li>Clarify any ambiguous or vague ideas or principles that may apply
to the case or the issue in question.</li>

<li>If possible, apply already existing, ethically acceptable
principles, laws, rules, and practices (the &ldquo;received policy
cluster&rdquo;) that govern human behavior in the given
society.</li>

<li>If ethically acceptable precedents, traditions and policies are
insufficient to settle the question or deal with the case, use the
purpose of a human life plus the great principles of justice to find a
solution that fits as well as possible into the ethical traditions of
the given society.</li>

</ol>

<p>

In an essentially just society &mdash; that is, in a society where the
&ldquo;received policy cluster&rdquo; is reasonably just &mdash; this
method of analyzing and resolving information ethics issues will
likely result in ethically good solutions that can be assimilated into
the society.</p>

<p>

Note that this way of doing information ethics does not require the
expertise of a trained philosopher (although such expertise might
prove to be helpful in many situations). Any adult who functions
successfully in a reasonably just society is likely to be familiar
with the existing customs, practices, rules and laws that govern a
person's behavior in that society and enable one to tell whether a
proposed action or policy would be accepted as ethical. So those who
must cope with the introduction of new information technology &mdash;
whether they are computer professionals, business people, workers,
teachers, parents, public-policy makers, or others &mdash; can and
should engage in information ethics by helping to integrate new
information technology into society in an ethically acceptable
way. Information ethics, understood in this <em>very broad sense</em>,
is too important to be left only to information professionals or to
philosophers. Wiener's information ethics interests, ideas and methods
were very broad, covering not only topics in the specific field of
&ldquo;computer ethics&rdquo;, as we would call it today, but also
issues in related areas that, today, are called &ldquo;agent
ethics&rdquo;, &ldquo;Internet ethics&rdquo;, and
&ldquo;nanotechnology ethics&rdquo;. The purview of Wiener's ideas and
methods is even broad enough to encompass subfields like journalism
ethics, library ethics, and the ethics of bioengineering.</p>

<p>

Even in the late 1940s, Wiener made it clear that, on his view, the
integration into society of the newly invented computing and
information technology would lead to the remaking of society &mdash;
to &ldquo;the second industrial revolution&rdquo; &mdash; &ldquo;the
automatic age&rdquo;. It would affect every walk of life, and would be
a multi-faceted, on-going process requiring decades of effort. In
Wiener's own words, the new information technology had placed human
beings &ldquo;in the presence of another social potentiality of
unheard-of importance for good and for evil.&rdquo; (1948, p. 27)
However, because he did not think of himself as creating a new branch
of ethics, Wiener did not coin names, such as &ldquo;computer
ethics&rdquo; or &ldquo;information ethics&rdquo;, to describe what he
was doing. These terms &mdash; beginning with &ldquo;computer
ethics&rdquo; &mdash; came into common use years later, starting in
the mid 1970s with the work of Walter Maner.</p>

<p>

Today, the &ldquo;information age&rdquo; that Wiener predicted half a
century ago has come into existence; and the metaphysical and
scientific foundation for information ethics that he laid down
continues to provide insight and effective guidance for understanding
and resolving ethical challenges engendered by information
technologies of all kinds.</p>

<h3><a name="DefComEth">1.2 Defining Computer Ethics</a></h3>

<p>

In 1976, nearly three decades after the publication of Wiener's
book <em>Cybernetics</em>, Walter Maner noticed that the ethical
questions and problems considered in his Medical Ethics course at Old
Dominion University often became more complicated or significantly
altered when computers got involved. Sometimes the addition of
computers, it seemed to Maner, actually generated <em>wholly new
ethics problems that would not have existed if computers had not been
invented</em>. He concluded that there should be a new branch of
applied ethics similar to already existing fields like medical ethics
and business ethics; and he decided to name the proposed new field
&ldquo;computer ethics&rdquo;. (At that time, Maner did not know about
the computer ethics works of Norbert Wiener.) He defined the proposed
new field as one that studies ethical problems &ldquo;aggravated,
transformed or created by computer technology&rdquo;. He developed an
experimental computer ethics course designed primarily for students in
university-level computer science programs. His course was a success,
and students at his university wanted him to teach it regularly. He
complied with their wishes and also created, in 1978, a &ldquo;starter
kit&rdquo; on teaching computer ethics, which he prepared for
dissemination to attendees of workshops that he ran and speeches that
he gave at philosophy conferences and computing science conferences in
America. In 1980, Helvetia Press and the National Information and
Resource Center on Teaching Philosophy published Maner's computer
ethics &ldquo;starter kit&rdquo; as a monograph (Maner 1980). It
contained curriculum materials and pedagogical advice for university
teachers. It also included a rationale for offering such a course in a
university, suggested course descriptions for university catalogs, a
list of course objectives, teaching tips, and discussions of topics
like privacy and confidentiality, computer crime, computer decisions,
technological dependence and professional codes of ethics. During the
early 1980s, Maner's <em>Starter Kit</em> was widely disseminated by
Helvetia Press to colleges and universities in America and
elsewhere. Meanwhile Maner continued to conduct workshops and teach
courses in computer ethics. As a result, a number of scholars,
especially philosophers and computer scientists, were introduced to
computer ethics because of Maner's trailblazing efforts.</p>

<h4>The &ldquo;uniqueness debate&rdquo;</h4>

<p>

While Maner was developing his new computer ethics course in the
mid-to-late 1970s, a colleague of his in the Philosophy Department at
Old Dominion University, Deborah Johnson, became interested in his
proposed new field. She was especially interested in Maner's view that
computers generate <em>wholly new</em> ethical problems, for she did
not believe that this was true. As a result, Maner and Johnson began
discussing ethics cases that allegedly involved <em>new</em> problems
brought about by computers. In these discussions, Johnson granted that
computers did indeed transform old ethics problems in interesting and
important ways &mdash; that is, &ldquo;give them a new twist&rdquo;
&mdash; but she did <em>not</em> agree that computers
generated <em>ethically unique</em> problems that had never been seen
before. The resulting Maner-Johnson discussion initiated a fruitful
series of comments and publications on the nature and uniqueness of
computer ethics &mdash; a series of scholarly exchanges that started
with Maner and Johnson and later spread to other scholars. The
following passage, from Maner's ETHICOMP95 keynote address, drew a
number of other people into the discussion:</p>

<blockquote>

I have tried to show that there are issues and problems that are
unique to computer ethics. For all of these issues, there was an
essential involvement of computing technology. Except for this
technology, these issues would not have arisen, or would not have
arisen in their highly altered form. The failure to find satisfactory
non-computer analogies testifies to the uniqueness of these
issues. The lack of an adequate analogy, in turn, has interesting
moral consequences. Normally, when we confront unfamiliar ethical
problems, we use analogies to build conceptual bridges to similar
situations we have encountered in the past. Then we try to transfer
moral intuitions across the bridge, from the analog case to our
current situation. Lack of an effective analogy forces us to discover
new moral values, formulate new moral principles, develop new
policies, and find new ways to think about the issues presented to
us. (Maner 1996, p. 152)

</blockquote>

<p>

Over the decade that followed this provocative passage, the extended
&ldquo;uniqueness debate&rdquo; led to a number of useful
contributions to computer and information ethics. (For some example
publications, see Johnson 1985, 1994, 1999, 2001; Maner 1980, 1996,
1999; Gorniak-Kocikowska 1996; Tavani 2002, 2005; Himma 2003; Floridi
and Sanders 2004; Mather 2005; and Bynum 2006, 2007.)</p>


<h4>An agenda-setting textbook</h4>

<p>

By the early 1980s, Johnson had joined the staff of Rensselaer
Polytechnic Institute and had secured a grant to prepare a set of
teaching materials &mdash; pedagogical modules concerning computer
ethics &mdash; that turned out to be very successful. She incorporated
them into a textbook, <em>Computer Ethics</em>, which was published in
1985 (Johnson 1985).  On page 1, she noted that computers &ldquo;pose
new versions of standard moral problems and moral dilemmas,
exacerbating the old problems, and forcing us to apply ordinary moral
norms in uncharted realms.&rdquo; She did <em>not</em> grant Maner's
claim, however, that computers create <em>wholly new</em> ethical
problems. Instead, she described computer ethics issues as old ethical
problems that are &ldquo;given a new twist&rdquo; by computer
technology.</p>

<p>

Johnson's book <em>Computer Ethics</em> was the first major textbook
in the field, and it quickly became the primary text used in computer
ethics courses offered at universities in English-speaking
countries. For more than a decade, her textbook set the computer
ethics research agenda on topics, such as ownership of software and
intellectual property, computing and privacy, responsibility of
computer professionals, and fair distribution of technology and human
power. In later editions (1994, 2001), Johnson added new ethical
topics like &ldquo;hacking&rdquo; into people's computers without
their permission, computer technology for persons with disabilities,
and the Internet's impact upon democracy.</p>

<p>

Also in later editions of <em>Computer Ethics</em>, Johnson continued
the &ldquo;uniqueness-debate&rdquo; discussion, noting for example
that new information technologies provide new ways to
&ldquo;instrument&rdquo; human actions. Because of this, she agreed
with Maner that new <em>specific</em> ethics questions had been
generated by computer technology &mdash; for example, &ldquo;Should
ownership of software be protected by law?&rdquo; or &ldquo;Do huge
databases of personal information threaten privacy?&rdquo; &mdash; but
she argued that such questions are merely &ldquo;new species of old
moral issues&rdquo;, such as protection of human privacy or ownership
of intellectual property. They are <em>not</em>, she
insisted, <em>wholly new</em> ethics problems requiring additions to
traditional ethical theories, as Maner had claimed (Maner 1996).</p>
 

<h4>1.3 An Influential Computer Ethics Theory</h4>

<p>

The year 1985 was a &ldquo;watershed year&rdquo; in the history of
computer ethics, not only because of the appearance of Johnson's
agenda-setting textbook, but also because James Moor's classic paper,
&ldquo;What Is Computer Ethics?&rdquo; was published in a special
computer-ethics issue of the
journal 
 <em>Metaphilosophy</em>.<sup>[<a href="notes.html#2" name="note-2">2</a>]</sup>
 There Moor provided an account of the nature of computer ethics that
was broader and more ambitious than the definitions of Maner or
Johnson. He went beyond descriptions and examples of computer ethics
problems by offering an explanation of <em>why</em> computing
technology raises so many ethical questions compared to other kinds of
technology. Moor's explanation of the revolutionary power of computer
technology was that computers are &ldquo;logically
malleable&rdquo;:</p>

<blockquote>

Computers are logically malleable in that they can be shaped and
molded to do any activity that can be characterized in terms of
inputs, outputs and connecting logical operations &hellip;&nbsp;. Because
logic applies everywhere, the potential applications of computer
technology appear limitless. The computer is the nearest thing we have
to a universal tool. Indeed, the limits of computers are largely the
limits of our own creativity. (Moor, 1985, 269)

</blockquote>

<p>

The logical malleability of computer technology, said Moor, makes it
possible for people to do a vast number of things that they were not
able to do before. Since no one could do them before, the question
never arose as to whether one <em>ought</em> to do them. In addition,
because they could not be done before, no laws or standards of good
practice or specific ethical rules were established to govern
them. Moor called such situations &ldquo;policy vacuums&rdquo;, and
some of them might generate &ldquo;conceptual muddles&rdquo;:</p>

<blockquote>

A typical problem in computer ethics arises because there is a policy
vacuum about how computer technology should be used. Computers provide
us with new capabilities and these in turn give us new choices for
action. Often, either no policies for conduct in these situations
exist or existing policies seem inadequate. A central task of computer
ethics is to determine what we should do in such cases, that is,
formulate policies to guide our actions &hellip;&nbsp;. One difficulty is that
along with a policy vacuum there is often a conceptual
vacuum. Although a problem in computer ethics may seem clear
initially, a little reflection reveals a conceptual muddle. What is
needed in such cases is an analysis that provides a coherent
conceptual framework within which to formulate a policy for
action. (Moor, 1985, 266)

</blockquote>

<p>

In the late 1980s, Moor's &ldquo;policy vacuum&rdquo; explanation of
the need for computer ethics and his account of the revolutionary
&ldquo;logical malleability&rdquo; of computer technology quickly
became very influential among a growing number of computer ethics
scholars. He added additional ideas in the 1990s, including the
important notion of <em>core human values</em>: According to Moor,
some human values &mdash; such as <em>life, health, happiness,
security, resources, opportunities, and knowledge</em> &mdash; are so
important to the continued survival of any community that essentially
all communities do value them. Indeed, if a community did <em>not</em>
value the &ldquo;core values&rdquo;, it soon would cease to
exist. Moor used &ldquo;core values&rdquo; to examine computer ethics
topics like privacy and security (Moor 1997), and to add an account of
justice, which he called &ldquo;just consequentialism&rdquo; (Moor,
1999), a theory that combines &ldquo;core values&rdquo; and
consequentialism with Bernard Gert's deontological notion of
&ldquo;moral impartiality&rdquo; using &ldquo;the blindfold of
justice&rdquo; (Gert,1998).</p>

<p>

Moor's approach to computer ethics is a practical theory that provides
a broad perspective on the nature of the &ldquo;information
revolution&rdquo;. By using the notions of &ldquo;logical
malleability&rdquo;, &ldquo;policy vacuums&rdquo;, &ldquo;conceptual
muddles&rdquo;, &ldquo;core values&rdquo; and &ldquo;just
consequentialism&rdquo;, he provides the following problem-solving
method:</p>

<ol>

<li>Identify a policy vacuum generated by computing technology.</li>

<li>Eliminate any conceptual muddles.</li>

<li>Use the core values and the ethical resources of just
consequentialism to revise existing &mdash; but inadequate &mdash;
policies, or else to create <em>new</em> policies that justly
eliminate the vacuum and resolve the original ethical issue.
</li>

</ol>

<p>

The third step is accomplished by combining deontology and
consequentialism &mdash; which traditionally have been considered
incompatible rival ethics theories &mdash; to achieve the following
practical results:</p>

<blockquote>

If the blindfold of justice is applied to [suggested] computing
policies, some policies will be regarded as unjust by all rational,
impartial people, some policies will be regarded as just by all
rational, impartial people, and some will be in dispute. This approach
is good enough to provide just constraints on consequentialism. We
first require that all computing policies pass the impartiality
test. Clearly, our computing policies should not be among those that
every rational, impartial person would regard as unjust. Then we can
further select policies by looking at their beneficial
consequences. We are not ethically required to select policies with
the best possible outcomes, but we can assess the merits of the
various policies using consequentialist considerations and we may
select very good ones from those that are just. (Moor, 1999,
68)

</blockquote>

<h4>1.4 Computing and Human Values</h4>

<p>

Beginning with the computer ethics works of Norbert Wiener (1948,
1950, 1963), a common thread has run through much of the history of
computer ethics; namely, concern for <em>protecting and advancing
central human values, such a life, health, security, happiness,
freedom, knowledge, resources, power and opportunity.</em> Thus, most
of the specific issues that Wiener dealt with are cases of defending
or advancing such values. For example, by working to prevent massive
unemployment caused by robotic factories, Wiener tried to preserve
security, resources and opportunities for factory workers. Similarly,
by arguing against the use of decision-making war-game machines,
Wiener tried to diminish threats to security and peace.</p>

<p>

This &ldquo;human-values approach&rdquo; to computer ethics has been
very fruitful. It has served, for example, as an organizing theme for
major computer-ethics conferences, such as the 1991 National
Conference on Computing and Values at Southern Connecticut State
University (see the section below on &ldquo;exponential
growth&rdquo;), which was devoted to the impacts of computing
upon <em>security, property, privacy, knowledge, freedom and
 opportunities</em>.<sup>[<a href="notes.html#3" name="note-3">3</a>]</sup>
 In the late 1990s, a similar approach
to computer ethics, called &ldquo;value-sensitive computer
design&rdquo;, emerged based upon the insight that potential
computer-ethics problems can be avoided, while new technology is under
development, by <em>anticipating possible harm to human values and
designing new technology from the very beginning in ways that prevent
such harm.</em> (See, for example, Friedman and Nissenbaum, 1996;
Friedman, 1997; Brey, 2000; Introna and Nissenbaum, 2000; Introna,
2005a; Flanagan, et al., 2007.)</p>

<h4>1.5 Professional Ethics and Computer Ethics</h4>

<p>

In the early 1990s, a different emphasis within computer ethics was
advocated by Donald Gotterbarn. He believed that computer ethics
should be seen as a <em>professional</em> ethics devoted to the
development and advancement of standards of good practice and codes of
conduct for computing professionals. Thus, in 1991, in the article
&ldquo;Computer Ethics: Responsibility Regained&rdquo;, Gotterbarn
said:</p>

<blockquote>

There is little attention paid to the domain of professional ethics
&mdash; the values that guide the day-to-day activities of computing
professionals in their role as professionals. By computing
professional I mean anyone involved in the design and development of
computer artifacts. &hellip; The ethical decisions made during the
development of these artifacts have a direct relationship to many of
the issues discussed under the broader concept of computer
ethics. (Gotterbarn, 1991)

</blockquote>

<p>

Throughout the 1990s, with this aspect of computer ethics in mind,
Gotterbarn worked with other professional-ethics advocates (for
example, Keith Miller, Dianne Martin, Chuck Huff and Simon Rogerson)
in a variety of projects to advance professional responsibility among
computer practitioners. Even before 1991, Gotterbarn had been part of
a committee of the ACM (Association for Computing Machinery) to create
the third version of that organization's &ldquo;Code of Ethics and
Professional Conduct&rdquo; (adopted by the ACM in 1992, see Anderson,
et al., 1993). Later, Gotterbarn and colleagues in the ACM and the
Computer Society of the IEEE (Institute of Electrical and Electronic
Engineers) developed licensing standards for software engineers. In
addition, Gotterbarn headed a joint taskforce of the IEEE and ACM to
create the &ldquo;Software Engineering Code of Ethics and Professional
Practice&rdquo; (adopted by those organizations in 1999; see
Gotterbarn, Miller and Rogerson, 1997).</p>

<p>

In the late 1990s, Gotterbarn created the Software Engineering Ethics
Research Institute (SEERI) at East Tennessee State University (see
http://seeri.etsu.edu/); and in the early 2000s, together with Simon
Rogerson, he developed a computer program called SoDIS (Software
Development Impact Statements) to assist individuals, companies and
organizations in the preparation of ethical &ldquo;stakeholder
analyses&rdquo; for determining likely ethical impacts of software
development projects (Gotterbarn and Rogerson, 2005). These and many
other projects focused attention upon <em>professional
responsibility</em> and advanced the professionalization and ethical
maturation of computing practitioners. (See the bibliography below for
works by R. Anderson, D. Gotterbarn, C. Huff, C. D. Martin, K. Miller,
and S. Rogerson.)</p>

<h4>1.6 Uniqueness and Global Information Ethics</h4>

<p>

In 1995, in her ETHICOMP95 presentation &ldquo;The Computer Revolution
and the Problem of Global Ethics&rdquo;, Krystyna
G&oacute;rniak-Kocikowska, made a startling prediction (see
G&oacute;rniak, 1996). She argued that computer ethics eventually will
evolve into a global ethic applicable in every culture on
earth. According to this &ldquo;G&oacute;rniak hypothesis&rdquo;,
regional ethical theories like Europe's Benthamite and Kantian
systems, as well as the diverse ethical systems embedded in other
cultures of the world, all derive from &ldquo;local&rdquo; histories
and customs and are unlikely to be applicable world-wide. Computer and
information ethics, on the other hand, G&oacute;rniak argued, has the
potential to provide a global ethic suitable for the Information
Age:</p>

<ul>

<li>a new ethical theory is likely to emerge from computer ethics in
response to the computer revolution. The newly emerging field of
information ethics, therefore, is much more important than even its
founders and advocates believe. (p. 177)</li>

<li>The very nature of the Computer Revolution indicates that the
ethic of the future will have a global character. It will be global in
a spatial sense, since it will encompass the entire globe. It will
also be global in the sense that it will address the totality of human
actions and relations. (p.179)</li>

<li>Computers do not know borders. Computer networks &hellip; have a
truly global character. Hence, when we are talking about computer
ethics, we are talking about the emerging global ethic. (p. 186)</li>

<li>the rules of computer ethics, no matter how well thought through,
will be ineffective unless respected by the vast majority of or maybe
even all computer users. &hellip; In other words, computer ethics will
become universal, it will be a global ethic. (p.187)</li>

</ul>

<p>

The provocative &ldquo;G&oacute;rniak hypothesis&rdquo; was a
significant contribution to the ongoing &ldquo;uniqueness
debate&rdquo;, and it reinforced Maner's claim &mdash; which he made
at the same ETHICOMP95 conference in his keynote address &mdash; that
information technology &ldquo;forces us to discover new moral values,
formulate new moral principles, develop new policies, and find new
ways to think about the issues presented to us.&rdquo; (Maner 1996,
p. 152) G&oacute;rniak did not speculate about the globally relevant
concepts and principles that would evolve from information ethics. She
merely predicted that such a theory would emerge over time because of
the global nature of the Internet and the resulting ethics
conversation among all the cultures of the world.</p>

<h4>1.7 Information Ethics</h4>

<p>

Some important recent developments, which began after 1995, seem to be
confirming G&oacute;rniak's hypothesis &mdash; in particular, the
<em>information ethics</em> theory of Luciano Floridi (see, for
example, Floridi, 1999 and Floridi, 2005a) and the &ldquo;Flourishing
Ethics&rdquo; theory that combines ideas from Aristotle, Wiener, Moor
and Floridi (see Section 1.8 below, and also Bynum, 2006).</p>

<p>

In developing his information ethics theory (henceforth <em>FIE</em>),
Floridi argued that the purview of computer ethics &mdash; indeed of
ethics in general &mdash; should be widened to include much more than
simply human beings, their actions, intentions and characters. He
offered FIE as another &ldquo;macroethics&rdquo; (his term) which
is <em>similar</em> to utilitarianism, deontologism, contractualism, and
virtue ethics, because it is intended to be applicable to all ethical
situations. On the other hand, IE is <em>different</em> from
these more traditional Western theories because it is <em>not intended
to replace them</em>, but rather to <em>supplement them with further
ethical considerations</em> that go beyond the traditional theories,
and that can be overridden, sometimes, by traditional ethical
considerations. (Floridi, 2006)</p>

<p>

The name &lsquo;information ethics&rsquo; is appropriate to Floridi's
theory, because it treats everything that exists as
&ldquo;informational&rdquo; objects or processes:</p>

<blockquote>

 <p>
 [All] entities will be described as clusters of data, that is, as
informational objects. More precisely, [any existing entity] will be a
discrete, self-contained, encapsulated package containing</p>

 <ol type="i">

 <li>the appropriate data structures, which constitute the nature of
the entity in question, that is, the state of the object, its unique
identity and its attributes; and</li>

 <li>a collection of operations, functions, or procedures, which are
activated by various interactions or stimuli (that is, messages
received from other objects or changes within itself) and
correspondingly define how the object behaves or reacts to
them.</li>

  </ol>

 <p>
 At this level of abstraction, informational systems as such, rather
than just living systems in general, are raised to the role of agents
and patients of any action, with environmental processes, changes and
interactions equally described informationally. (Floridi 2006,
9-10)</p>

</blockquote>

<p>

Since everything that exists, according to FIE, is an informational
object or process, he calls the totality of all that exists &mdash;
the universe considered as a whole &mdash; &ldquo;the
infosphere&rdquo;. Objects and processes in the infosphere can be
significantly damaged or destroyed by altering their characteristic
data structures. Such damage or destruction Floridi calls
&ldquo;entropy&rdquo;, and it results in partial &ldquo;empoverishment
of the infosphere&rdquo;. <em>Entropy in this sense is an evil that
should be avoided or minimized</em>, and Floridi offers four
&ldquo;fundamental principles&rdquo;:</p>

<ol start="0">

<li>Entropy ought not to be caused in the infosphere (null law).</li>
<li>Entropy ought to be prevented in the infosphere. </li>
<li>Entropy ought to be removed from the infosphere. </li>
<li>The flourishing of informational entities as well as the whole infosphere ought
to be promoted by preserving, cultivating and enriching their properties.</li>

</ol>

<p>

FIE is based upon the idea that everything in the infosphere has at
least a minimum worth that should be ethically respected, even if that
worth can be overridden by other considerations:</p>

<blockquote>

FIE suggests that there is something even more elemental than life,
namely <em>being</em> &mdash; that is, the existence and flourishing
of all entities and their global environment &mdash; and something
more fundamental than suffering, namely <em>entropy</em>
&hellip;&nbsp;. FIE holds that <em>being</em>/information has an
intrinsic worthiness. It substantiates this position by recognizing
that any informational entity has a <em>Spinozian</em> right to
persist in its own status, and a <em>Constructionist</em> right to
flourish, i.e., to improve and enrich its existence and
essence. (Floridi 2006, p. 11)

</blockquote>

<p>

By construing every existing entity in the universe as
&ldquo;informational&rdquo;, with at least a minimal moral worth, FIE
can supplement traditional ethical theories and go beyond them by
shifting the focus of one's ethical attention away from the actions,
characters, and values of human agents toward the &ldquo;evil&rdquo;
(harm, dissolution, destruction) &mdash; &ldquo;entropy&rdquo; &mdash;
suffered by objects and processes in the infosphere. With this
approach, every existing entity &mdash; humans, other animals, plants,
organizations, even non-living artifacts, electronic objects in
cyberspace, pieces of intellectual property &mdash; can be interpreted
as potential agents that affect other entities, and as potential
patients that are affected by other entities. In this way, Floridi
treats FIE as a &ldquo;patient-based&rdquo;
non-anthropocentric ethical theory to be used in addition to the
traditional &ldquo;agent-based&rdquo; anthropocentric ethical theories
like utilitarianism, deontologism and virtue theory.</p>

<p>

FIE, with its emphasis on &ldquo;preserving and enhancing the
infosphere&rdquo;, enables Floridi to provide, among other things, an
insightful and practical ethical theory of robot behavior and the
behavior of other &ldquo;artificial agents&rdquo; like softbots and
cyborgs.  (See, for example, Floridi and Sanders, 2004.) FIE is an
important component of a more ambitious project covering the entire
new field of the Philosophy of Information.</p>

<h4>1.8 Exponential Growth</h4>

<p>

The paragraphs above describe key contributions to &ldquo;the history
of ideas&rdquo; in information and computer ethics, but the history of
a discipline includes much more. The birth and development of a new
academic field require cooperation among a &ldquo;critical mass&rdquo;
of scholars, plus the creation of university courses, research
centers, conferences, and academic journals. In this regard, the year
1985 was pivotal for information and computer ethics. The publication
of Johnson's textbook, <em>Computer Ethics</em>, plus a special issue
of the journal <em>Metaphilosophy</em> (October 1985) &mdash;
including especially Moor's article &ldquo;What Is Computer
Ethics?&rdquo; &mdash; provided excellent curriculum materials and a
conceptual foundation for the field. In addition, Maner's earlier
trailblazing efforts, and those of other people who had been inspired
by Maner, had generated a &ldquo;ready-made audience&rdquo; of
enthusiastic computer science and philosophy scholars. The stage was
set for exponential growth.</p>

<p>

In the United States, rapid growth occurred in information and
computer ethics beginning in the mid-1980s. In 1987 the Research
Center on Computing &amp; Society (RCCS) was founded at Southern
Connecticut State University. Shortly thereafter, the Director (the
present author) joined with Walter Maner to organize &ldquo;the
National Conference on Computing and Values&rdquo; (NCCV), an
NSF-funded conference to bring together computer scientists,
philosophers, public policy makers, lawyers, journalists,
sociologists, psychologists, business people, and others. The goal was
to examine and push forward some of the major sub-areas of information
and computer ethics; namely, computer security, computers and privacy,
ownership of intellectual property, computing for persons with
disabilities, and the teaching of computer ethics. More than a dozen
scholars from several different disciplines joined with Bynum and
Maner to plan NCCV, which occurred in August 1991 at Southern
Connecticut State University. Four hundred people from thirty-two
American states and seven other countries attended; and the conference
generated a wealth of new computer ethics materials &mdash;
monographs, video programs and an extensive bibliography &mdash; that
were disseminated to hundreds of colleges and universities during the
following two years.</p>

<p>

In that same decade, professional ethics advocates, such as Donald
Gotterbarn, Keith Miller and Dianne Martin &mdash; and professional
organizations, such as Computer Professionals for Social
Responsibility (www.cpsr.org), the Electronic Frontier Foundation
(www.eff.org), and the Special Interest Group on Computing and Society
(SIGCAS) of the ACM &mdash; spearheaded projects focused upon
professional responsibility for computer practitioners. Information
and computer ethics became a required component of undergraduate
computer science programs that were nationally accredited by the
Computer Sciences Accreditation Board. In addition, the annual
&ldquo;Computers, Freedom and Privacy&rdquo; conferences began in 1991
(see www.cfp.org), and the ACM adopted a new version of its Code of
Ethics and Professional Conduct in 1992.</p>

<p>

In 1995, rapid growth of information and computer ethics spread to
Europe when the present author joined with Simon Rogerson of De
Montfort University in Leicester, England to create the Centre for
Computing and Social Responsibility (www.ccsr.cse.dmu.ac.uk) and to
organize the first computer ethics conference in Europe, ETHICOMP95.
That conference included attendees from fourteen different countries,
mostly in Europe, and it became a key factor in generating a
&ldquo;critical mass&rdquo; of computer ethics scholars in
Europe. After 1995, every 18 months, another ETHICOMP conference was
held in a different European country, including Spain (1996), the
Netherlands (1998), Italy (1999), Poland (2001), Portugal (2002),
Greece (2004) and Sweden (2005). In addition, in 1999, with assistance
from Bynum and Rogerson, the Australian scholars John Weckert and
Christopher Simpson created the Australian Institute of Computer
Ethics (aice.net.au) and organized AICEC99 (Melbourne, Australia),
which was the first international computer ethics conference south of
the equator. In 2007 Rogerson and Bynum also headed ETHICOMP2007 in
Tokyo, Japan and an ETHICOMP &ldquo;Working Conference&rdquo; in
Kunming, China to help spread interest in information ethics to
Asia.</p>

<p>

A central figure in the rapid growth of information and computer
ethics in Europe was Simon Rogerson. In addition to creating the
Centre for Computing and Social Responsibility at De Montfort
University and co-heading the influential ETHICOMP conferences, he
also (1) added computer ethics to De Montfort University's curriculum,
(2) created a graduate program with advanced computer ethics degrees,
including the PhD, and (3) co-founded and co-edited (with Ben
Fairweather) two computer ethics journals &mdash; <em>The Journal of
Information, Communication and Ethics in Society</em> in 2003 (see the
link the Other Internet Resources section), and the electronic
journal <em>The ETHICOMP Journal</em> in 2004 (see Other Internet
Resources). Rogerson also served on the Information Technology
Committee of the British Parliament, and participated in several
computer ethics projects with agencies of the European Union.</p>

<p>

Other important computer ethics developments in Europe in the late
1990s and early 2000s included, for example, (1) Luciano Floridi's
creation of the Information Ethics Research Group at Oxford University
in the mid 1990s; (2) Jeroen van den Hoven's founding, in 1997, of the
CEPE (Computer Ethics: Philosophical Enquiry) series of computer
ethics conferences, which occur alternately in Europe and America; (3)
van den Hoven's creation of the journal <em>Ethics and Information
Technology</em> in 1999; (4) Rafael Capurro's creation of the
International Center for Information Ethics (icie.zkm.de) in 1999; (5)
Capurro's creation of the journal <em>International Review of
Information Ethics</em> in 2004; and Bernd Carsten Stahl's creation
of <em>The International Journal of Technology and Human
Interaction</em> in 2005.</p>

<p>

In summary, since 1985 computer ethics developments have proliferated
exponentially with new conferences and conference series, new
organizations, new research centers, new journals, textbooks, web
sites, university courses, university degree programs, and
distinguished professorships. Additional &ldquo;sub-fields&rdquo; and
topics in information and computer ethics continually emerge as
information technology itself grows and proliferates. Recent new
topics include on-line ethics, &ldquo;agent&rdquo; ethics (robots,
softbots), cyborg ethics (part human, part machine), the &ldquo;open
source movement&rdquo;, electronic government, global information
ethics, information technology and genetics, computing for developing
countries, computing and terrorism, ethics and nanotechnology, to name
only a few examples. (For specific publications and examples, see the
list of selected resources below.)</p>

<p>

Compared to many other scholarly disciplines, the field of computer
ethics is very young. It has existed only since the late 1940s when
Norbert Wiener created it. During the first three decades, it grew
very little because Wiener's insights were far ahead of everyone
else's. In the past 25 years, however, information and computer ethics
has grown exponentially in the industrialized world, and the rest of
the world has begun to take notice.</p>

<h2><a name="ExaTopComEth">2. Example Topics in Computer Ethics</a></h2>

<p>No matter which re-definition of computer ethics one chooses, the best
way to understand the nature of the field is through some
representative examples of the issues and problems that have attracted
research and scholarship. Consider, for example, the following topics: </p>

<ul>
<li><a href="#2.1">2.1 Computers in the Workplace</a></li>

<li><a href="#2.2">2.2 Computer Crime</a></li>

<li><a href="#2.3">2.3 Privacy and Anonymity</a></li>

<li><a href="#2.4">2.4 Intellectual Property</a></li>

<li><a href="#2.5">2.5 Professional Responsibility</a></li>

<li><a href="#2.6">2.6 Globalization</a></li>

<li><a href="#2.7">2.7 The Metaethics of Computer Ethics</a></li>
</ul>

<p>(See also the wide range of topics included in the recent anthology
[Spinello and Tavani, 2001].) </p>

<h3><a name="ComWor">2.1 Computers in the Workplace</a></h3>

<p>As a &ldquo;universal tool&rdquo; that can, in principle, perform
almost any task, computers obviously pose a threat to jobs. Although
they occasionally need repair, computers don't require sleep, they
don't get tired, they don't go home ill or take time off for rest and
relaxation. At the same time, computers are often far more efficient
than humans in performing many tasks. Therefore, economic incentives
to replace humans with computerized devices are very high. Indeed, in
the industrialized world many workers already have been replaced by
computerized devices &mdash; bank tellers, auto workers, telephone
operators, typists, graphic artists, security guards, assembly-line
workers, and on and on. In addition, even professionals like medical
doctors, lawyers, teachers, accountants and psychologists are finding
that computers can perform many of their traditional professional
duties quite effectively.</p>


<p>

The employment outlook, however, is not all bad. Consider, for
example, the fact that the computer industry already has generated a
wide variety of new jobs: hardware engineers, software engineers,
systems analysts, webmasters, information technology teachers, computer
sales clerks, and so on. Thus it appears that, in the short run,
computer-generated unemployment will be an important social problem;
but in the long run, information technology will create many more jobs
than it eliminates.</p>

<p>

Even when a job is not eliminated by computers, it can be radically
altered. For example, airline pilots still sit at the controls of
commercial airplanes; but during much of a flight the pilot simply
watches as a computer flies the plane. Similarly, those who prepare
food in restaurants or make products in factories may still have jobs;
but often they simply push buttons and watch as computerized devices
actually perform the needed tasks. In this way, it is possible for
computers to cause &ldquo;de-skilling&rdquo; of workers, turning them
into passive observers and button pushers. Again, however, the picture
is not all bad because computers also have generated new jobs which
require new sophisticated skills to perform &mdash; for example,
&ldquo;computer assisted drafting&rdquo; and &ldquo;keyhole&rdquo;
surgery.</p>

<p>

Another workplace issue concerns health and safety. As Forester and
Morrison point out [Forester and Morrison, 140-72, Chapter 8], when
information technology is introduced into a workplace, it is important
to consider likely impacts upon health and job satisfaction of workers
who will use it. It is possible, for example, that such workers will
feel stressed trying to keep up with high-speed computerized devices
&mdash; or they may be injured by repeating the same physical movement
over and over &mdash; or their health may be threatened by radiation
emanating from computer monitors. These are just a few of the social
and ethical issues that arise when information technology is
introduced into the workplace.</p>

<h3><a name="ComCri">2.2 Computer Crime</a></h3>

<p>

In this era of computer &ldquo;viruses&rdquo; and international spying
by &ldquo;hackers&rdquo; who are thousands of miles away, it is clear
that computer security is a topic of concern in the field of Computer
Ethics. The problem is not so much the physical security of the
hardware (protecting it from theft, fire, flood, etc.), but rather
&ldquo;logical security&rdquo;, which Spafford, Heaphy and Ferbrache
[Spafford, et al, 1989] divide into five aspects: </p>

<ol>

<li>Privacy and confidentiality</li>

<li>Integrity &mdash; assuring that data and programs are not modified
without proper authority</li>

<li>Unimpaired service</li>

<li>Consistency &mdash; ensuring that the data and behavior we see today
will be the same tomorrow</li>

<li>Controlling access to resources</li>

</ol>

<p>

Malicious kinds of software, or &ldquo;programmed threats&rdquo;,
provide a significant challenge to computer security. These include
&ldquo;viruses&rdquo;, which cannot run on their own, but rather are
inserted into other computer programs; &ldquo;worms&rdquo; which can
move from machine to machine across networks, and may have parts of
themselves running on different machines; &ldquo;Trojan horses&rdquo;
which appear to be one sort of program, but actually are doing damage
behind the scenes; &ldquo;logic bombs&rdquo; which check for
particular conditions and then execute when those conditions arise;
and &ldquo;bacteria&rdquo; or &ldquo;rabbits&rdquo; which multiply
rapidly and fill up the computer's memory. </p>

<p>

Computer crimes, such as embezzlement or planting of logic bombs,
are normally committed by trusted personnel who have permission to use
the computer system. Computer security, therefore, must also be
concerned with the actions of trusted computer users.</p>

<p>

Another major risk to computer security is the so-called
&ldquo;hacker&rdquo; who breaks into someone's computer system without
permission. Some hackers intentionally steal data or commit vandalism,
while others merely &ldquo;explore&rdquo; the system to see how it
works and what files it contains. These &ldquo;explorers&rdquo; often
claim to be benevolent defenders of freedom and fighters against
rip-offs by major corporations or spying by government agents. These
self-appointed vigilantes of cyberspace say they do no harm, and claim
to be helpful to society by exposing security risks. However every act
of hacking is harmful, because any known successful penetration of a
computer system requires the owner to thoroughly check for damaged or
lost data and programs. Even if the hacker did indeed make no changes,
the computer's owner must run through a costly and time-consuming
investigation of the compromised system [Spafford, 1992].</p>

<h3><a name="PriAno">2.3 Privacy and Anonymity</a></h3>

<p>

One of the earliest computer ethics topics to arouse public interest
was privacy. For example, in the mid-1960s the American government
already had created large databases of information about private
citizens (census data, tax records, military service records, welfare
records, and so on). In the US Congress, bills were introduced to
assign a personal identification number to every citizen and then
gather all the government's data about each citizen under the
corresponding ID number. A public outcry about &ldquo;big-brother
government&rdquo; caused Congress to scrap this plan and led the US
President to appoint committees to recommend privacy legislation. In
the early 1970s, major computer privacy laws were passed in the
USA. Ever since then, computer-threatened privacy has remained as a
topic of public concern.  The ease and efficiency with which computers
and computer networks can be used to gather, store, search, compare,
retrieve and share personal information make computer technology
especially threatening to anyone who wishes to keep various kinds of
&ldquo;sensitive&rdquo; information (e.g., medical records) out of the
public domain or out of the hands of those who are perceived as
potential threats. During the past decade, commercialization and rapid
growth of the internet; the rise of the world-wide-web; increasing
&ldquo;user-friendliness&rdquo; and processing power of computers; and
decreasing costs of computer technology have led to new privacy
issues, such as data-mining, data matching, recording of &ldquo;click
trails&rdquo; on the web, and so on [see Tavani, 1999].</p>

<p>

The variety of privacy-related issues generated by computer technology
has led philosophers and other thinkers to re-examine the concept of
privacy itself. Since the mid-1960s, for example, a number of scholars
have elaborated a theory of privacy defined as &ldquo;control over
personal information&rdquo; (see, for example, [Westin, 1967],
[Miller, 1971], [Fried, 1984] and [Elgesem, 1996]). On the other hand,
philosophers Moor and Tavani have argued that control of personal
information is insufficient to establish or protect privacy, and
&ldquo;the concept of privacy itself is best defined in terms of
restricted access, not control&rdquo; [Tavani and Moor, 2001] (see
also [Moor, 1997]).  In addition, Nissenbaum has argued that there is
even a sense of privacy in public spaces, or circumstances
&ldquo;other than the intimate.&rdquo; An adequate definition of
privacy, therefore, must take account of &ldquo;privacy in
public&rdquo; [Nissenbaum, 1998]. As computer technology rapidly
advances &mdash; creating ever new possibilities for compiling, storing,
accessing and analyzing information &mdash; philosophical debates about the
meaning of &ldquo;privacy&rdquo; will likely continue (see also
[Introna, 1997]).</p>

<p>

Questions of anonymity on the internet are sometimes discussed in
the same context with questions of privacy and the internet, because
anonymity can provide many of the same benefits as privacy. For
example, if someone is using the internet to obtain medical or
psychological counseling, or to discuss sensitive topics (for example,
AIDS, abortion, gay rights, venereal disease, political dissent),
anonymity can afford protection similar to that of privacy. Similarly,
both anonymity and privacy on the internet can be helpful in preserving
human values such as security, mental health, self-fulfillment and
peace of mind. Unfortunately, privacy and anonymity also can be
exploited to facilitate unwanted and undesirable computer-aided
activities in cyberspace, such as money laundering, drug trading,
terrorism, or preying upon the vulnerable (see [Marx, 2001] and
[Nissenbaum, 1999]).</p>

<h3><a name="IntPro">2.4 Intellectual Property</a></h3>

<p>One of the more controversial areas of computer ethics concerns the
intellectual property rights connected with software ownership. Some
people, like Richard Stallman who started the Free Software
Foundation, believe that software ownership should not be allowed at
all. He claims that all information should be free, and all programs
should be available for copying, studying and modifying by anyone who
wishes to do so [Stallman, 1993]. Others argue that software companies
or programmers would not invest weeks and months of work and
significant funds in the development of software if they could not get
the investment back in the form of license fees or sales [Johnson,
1992].  Today's software industry is a multibillion dollar part of the
economy; and software companies claim to lose billions of dollars per
year through illegal copying (&ldquo;software piracy&rdquo;). Many
people think that software should be ownable, but &ldquo;casual
copying&rdquo; of personally owned programs for one's friends should
also be permitted (see [Nissenbaum, 1995]). The software industry
claims that millions of dollars in sales are lost because of such
copying. Ownership is a complex matter, since there are several
different aspects of software that can be owned and three different
types of ownership: copyrights, trade secrets, and patents. One can
own the following aspects of a program:</p>

<ol>

<li>The &ldquo;source code&rdquo; which is written by the
programmer(s) in a high-level computer language like Java or C++.</li>

<li>The &ldquo;object code&rdquo;, which is a machine-language
translation of the source code.</li>

<li>The &ldquo;algorithm&rdquo;, which is the sequence of machine
commands that the source code and object code represent.</li>

<li>The &ldquo;look and feel&rdquo; of a program, which is the way the
program appears on the screen and interfaces with users.</li>

</ol>

<p>
A very controversial issue today is owning a patent on a computer
algorithm. A patent provides an exclusive monopoly on the use of the
patented item, so the owner of an algorithm can deny others use of the
mathematical formulas that are part of the algorithm. Mathematicians
and scientists are outraged, claiming that algorithm patents
effectively remove parts of mathematics from the public domain, and
thereby threaten to cripple science. In addition, running a
preliminary &ldquo;patent search&rdquo; to make sure that your
&ldquo;new&rdquo; program does not violate anyone's software patent is
a costly and time-consuming process. As a result, only very large
companies with big budgets can afford to run such a search. This
effectively eliminates many small software companies, stifling
competition and decreasing the variety of programs available to the
society [The League for Programming Freedom, 1992]. </p>

<h3><a name="ProRes">2.5 Professional Responsibility</a></h3>

<p>Computer professionals have specialized knowledge and often have
positions with authority and respect in the community. For this reason,
they are able to have a significant impact upon the world, including
many of the things that people value. Along with such power to change
the world comes the duty to exercise that power responsibly
[Gotterbarn, 2001]. Computer professionals find themselves in a variety
of professional relationships with other people [Johnson, 1994],
including: </p>

<blockquote>
<table>
<tr>
<td align="right">employer</td>
<td>&mdash;</td>
<td align="left">employee</td>
</tr>

<tr>
<td align="right">client</td>
<td>&mdash;</td>
<td align="left">professional</td>
</tr>

<tr>
<td align="right">professional</td>
<td>&mdash;</td>
<td align="left">professional</td>
</tr>

<tr>
<td align="right">society</td>
<td>&mdash;</td>
<td align="left">professional</td>
</tr>
</table>
</blockquote>

<p>These relationships involve a diversity of interests, and sometimes
these interests can come into conflict with each other. Responsible
computer professionals, therefore, will be aware of possible conflicts
of interest and try to avoid them. </p>

<p>

Professional organizations in the USA, like the Association for
Computing Machinery (ACM) and the Institute of Electrical and
Electronic Engineers (IEEE), have established codes of ethics,
curriculum guidelines and accreditation requirements to help computer
professionals understand and manage ethical responsibilities. For
example, in 1991 a Joint Curriculum Task Force of the ACM and IEEE
adopted a set of guidelines (&ldquo;Curriculum 1991&rdquo;) for
college programs in computer science. The guidelines say that a
significant component of computer ethics (in the broad sense) should
be included in undergraduate education in computer science [Turner,
1991].</p>

<p>

In addition, both the ACM and IEEE have adopted Codes of Ethics for
their members. The most recent ACM Code (1992), for example, includes
&ldquo;general moral imperatives&rdquo;, such as &ldquo;avoid harm to
others&rdquo; and &ldquo;be honest and trustworthy&rdquo;. And also
included are &ldquo;more specific professional responsibilities&rdquo;
like &ldquo;acquire and maintain professional competence&rdquo; and
&ldquo;know and respect existing laws pertaining to professional
work.&rdquo; The IEEE Code of Ethics (1990) includes such principles
as &ldquo;avoid real or perceived conflicts of interest whenever
possible&rdquo; and &ldquo;be honest and realistic in stating claims
or estimates based on available data.&rdquo;</p>

<p>

The Accreditation Board for Engineering Technologies (ABET) has long
required an ethics component in the computer engineering curriculum.
And in 1991, the Computer Sciences Accreditation Commission/Computer
Sciences Accreditation Board (CSAC/CSAB) also adopted the requirement
that a significant component of computer ethics be included in any
computer sciences degree granting program that is nationally accredited
[Conry, 1992].</p>

<p>

It is clear that professional organizations in computer science
recognize and insist upon standards of professional responsibility for
their members.</p>

<h3><a name="Glo">2.6 Globalization</a></h3>

<p>Computer ethics today is rapidly evolving into a broader and even more
important field, which might reasonably be called &ldquo;global information
ethics&rdquo;. Global networks like the Internet and especially the
world-wide-web are connecting people all over the earth. As Krystyna
Gorniak-Kocikowska perceptively notes in her paper, &ldquo;The Computer
Revolution and the Problem of Global Ethics&rdquo; [Gorniak-Kocikowska,
1996], for the first time in history, efforts to develop mutually
agreed standards of conduct, and efforts to advance and defend human
values, are being made in a truly global context. So, for the first
time in the history of the earth, ethics and values will be debated and
transformed in a context that is not limited to a particular geographic
region, or constrained by a specific religion or culture. This may very
well be one of the most important social developments in history.
Consider just a few of the global issues: </p>

<h4>Global Laws</h4>

<p>If computer users in the United States, for example, wish to
protect their freedom of speech on the internet, whose laws apply?
Nearly two hundred countries are already interconnected by the
internet, so the United States Constitution (with its First Amendment
protection for freedom of speech) is just a &ldquo;local law&rdquo; on
the internet &mdash; it does not apply to the rest of the world. How can
issues like freedom of speech, control of &ldquo;pornography&rdquo;,
protection of intellectual property, invasions of privacy, and many
others to be governed by law when so many countries are involved? If a
citizen in a European country, for example, has internet dealings with
someone in a far-away land, and the government of that land considers
those dealings to be illegal, can the European be tried by the courts
in the far-away country?</p>

<h4>Global Cyberbusiness</h4>

<p>The world is very close to having technology that can provide
electronic privacy and security on the internet sufficient to safely
conduct international business transactions. Once this technology is
in place, there will be a rapid expansion of global
&ldquo;cyberbusiness&rdquo;.  Nations with a technological
infrastructure already in place will enjoy rapid economic growth,
while the rest of the world lags behind. What will be the political
and economic fallout from rapid growth of global cyberbusiness? Will
accepted business practices in one part of the world be perceived as
&ldquo;cheating&rdquo; or &ldquo;fraud&rdquo; in other parts of the
world? Will a few wealthy nations widen the already big gap between
rich and poor? Will political and even military confrontations
emerge?</p>

<h4>Global Education</h4>

<p>If inexpensive access to the global information net is provided to
rich and poor alike &mdash; to poverty-stricken people in ghettos, to poor
nations in the &ldquo;third world&rdquo;, etc. &mdash; for the first time in
history, nearly everyone on earth will have access to daily news from
a free press; to texts, documents and art works from great libraries
and museums of the world; to political, religious and social practices
of peoples everywhere. What will be the impact of this sudden and
profound &ldquo;global education&rdquo; upon political dictatorships,
isolated communities, coherent cultures, religious practices, etc.? As
great universities of the world begin to offer degrees and knowledge
modules via the internet, will &ldquo;lesser&rdquo; universities be
damaged or even forced out of business?</p>

<h4>Information Rich and Information Poor</h4>

<p>

The gap between rich and poor nations, and even between rich and poor
citizens in industrialized countries, is already disturbingly wide. As
educational opportunities, business and employment opportunities,
medical services and many other necessities of life move more and more
into cyberspace, will gaps between the rich and the poor become even
worse?</p>

 

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Adam, A. (2000), &ldquo;Gender and Computer Ethics,&rdquo; Computers and
Society, 30(4): 17-24.</li>

<li>Adam, A. and J. Ofori-Amanfo (2000), &ldquo;Does Gender Matter in
Computer Ethics?&rdquo; <em>Ethics and Information Technology</em>, 2(1):
37-47.</li>

<li>Anderson, R, D. Johnson, D. Gotterbarn and J.
Perrolle (1993), &ldquo;Using the New ACM Code of Ethics in Decision
Making,&rdquo; <em>Communications of the ACM</em>,  36: 98-107.</li>

<li>Begg, M.M. (2005), &ldquo;Muslim Parents Guide: Making Responsible Use of
Information and Communication Technologies at Home,&rdquo; Centre for
Computing and Social Responsibility, De Montfort University,
Leicester, UK.</li>

<li>Bohman, James (2008), &ldquo;The Transformation of the Public
Sphere: Political Authority, Communicative Freedom, and Internet
Publics,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 66-92.</li>

<li>Brennan, G. and P. Pettit (2008), &ldquo;Esteem,
Identiiability, and the Internet,&rdquo; in J. van den Hoven and J.
Weckert (eds.), <em>Information Technology and Moral Philosophy</em>, Cambridge:
Cambridge University Press, 175-94.</li>

<li>Brey, P. (2001), &ldquo;Disclosive Computer Ethics,&rdquo; in R. Spinello
and H. Tavani (eds.), <em>Readings in CyberEthics</em>,  Sudbury, MA: Jones
and Bartlett.</li>

<li>Brey, P. (2006), &ldquo;Evaluating the Social and Cultural
Implications of the Internet,&rdquo; <em>Computers and Society</em>, 36(3):
41-44.</li>

<li>Bynum, T. (1982), &ldquo;A Discipline in its Infancy,&rdquo;
 <em>The Dallas Morning News</em>, January 12, 1982, D/1, D/6. </li>

<li>Bynum, T. (1999), &ldquo;The Development of Computer Ethics as
a Philosophical Field of Study,&rdquo; <em>The Australian Journal of
Professional and Applied Ethics</em>, 1(1): 1-29.</li>

<li>Bynum, T. (2000), &ldquo;The Foundation of Computer Ethics,&rdquo;
<em>Computers and Society</em>, 30(2): 6-13.</li>

<li>Bynum, T. (2004), &ldquo;Ethical Challenges to Citizens of the
&lsquo;Automatic Age&rsquo;: Norbert Wiener on the Information
Society,&rdquo; <em>Journal of Information, Communication and Ethics
in Society</em>, 2(2): 65-74.</li>

<li>Bynum, T. (2005), &ldquo;Norbert Wiener's Vision: the Impact of
the &lsquo;Automatic Age&rsquo; on our Moral Lives,&rdquo; in
R. Cavalier (ed.), <em>The Impact of the Internet on our Moral
Lives</em>, Albany, NY: SUNY Press, 11-25.</li>

<li>Bynum, T. (2006), &ldquo;Flourishing Ethics,&rdquo; <em>Ethics and
Information Technology</em>, 8(4): 157-173.</li>

<li>Bynum, T. (2007), &ldquo;Norbert Wiener and the Rise of
Information Ethics,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Moral Philosophy and Information Technology</em>,
Cambridge: Cambridge University Press.</li>

<li>Bynum, T. (2008), &ldquo;Norbert Weiner and the Rise of
Information Ethics,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 8-25.</li>

<li>Bynum, T. and P. Schubert (1997), &ldquo;How to do Computer Ethics
&mdash; A Case Study: The Electronic Mall Bodensee,&rdquo; in J. van
den Hoven (ed.), <em>Computer Ethics&mdash;Philosophical Enquiry</em>,
Rotterdam: Erasmus University Press, 85-95.</li>

<li>Capurro, R. (2007a), &ldquo;Information Ethics for and from Africa,&rdquo;
<em>International Review of Information Ethics</em>, 2007: 3-13.</li>

<li>Capurro, R. (2007b), &ldquo;Intercultural Information Ethics,&rdquo; in
R. Capurro, J. Fr&uuml;hbauer and T. Hausmanninger (eds.), 
<em>Localizing the Internet: Ethical Issues in Intercultural
Perspective</em>, (ICIE Series, Volume 4), Munich: Fink, 2007: 21-38.</li>

<li>Capurro, R. (2006), &ldquo;Towards an Ontological Foundation for
Information Ethics,&rdquo; <em>Ethics and Information Technology</em>,
8(4): 157-186.</li>

<li>Capurro, R. (2004), &ldquo;The German Debate on the Information Society,&rdquo;
<em>The Journal of Information, Communication and Ethics in
Society</em>, 2 (Supplement): 17-18.</li>

<li>Cavalier, R. (ed.) (2005), <em>The Impact of the Internet on Our Moral
Lives</em>, Albany, NY: SUNY Press.</li>

<li>Cocking, D. (2008), &ldquo;Plural Selves and Relational Identity:
Intimacy and Privacy Online,&rdquo; In J. van den Hoven and J.
Weckert (eds.), <em>Information Technology and Moral Philosophy</em>, Cambridge:
Cambridge University Press, 123-41.</li>

<li>Conry, S. (1992), &ldquo;Interview on Computer Science
Accreditation,&rdquo; in T. Bynum and J. Fodor
(creators), <em>Computer Ethics in the Computer Science
Curriculum</em> (a video program), Kingston, NY: Educational Media
Resources, Inc.</li>

<li>Edgar, S. (1997), <em>Morality and Machines: Perspectives on Computer
Ethics</em>, Sudbury, MA: Jones and Bartlett.</li>

<li>Elgesem, D. (1995), &ldquo;Data Privacy and Legal Argumentation,&rdquo;
<em>Communication and Cognition</em>, 28(1): 91-114.</li>

<li>Elgesem, D. (1996), &ldquo;Privacy, Respect for Persons, and Risk,&rdquo; in
C. Ess (ed.), <em>Philosophical Perspectives on Computer-Mediated
Communication</em>, Albany: SUNY Press, 45-66.</li>

<li>Elgesem, D. (2002), &ldquo;What is Special about the Ethical
Problems in Internet Research?&rdquo; <em>Ethics and Information
Technology</em>, 4(3): 195-203.</li>

<li>Elgesem, D. (2008), &ldquo;Information Technology Research
Ethics,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 354-75.</li>

<li>Ess, C. (1996), &ldquo;The Political Computer: Democracy, CMC, and
Habermas,&rdquo; in C. Ess (ed.), <em>Philosophical Perspectives on
Computer-Mediated Communication</em>, Albany: SUNY Press, 197-230.</li>

<li>Ess, C. (ed.) (2001a), <em>Culture, Technology, Communication:
Towards an Intercultural Global Village</em>, Albany: SUNY Press.</li>

<li>Ess, C. (2001b), &ldquo;What's Culture got to do with it? Cultural
Collisions in the Electronic Global Village,&rdquo; in C. Ess (ed.),
<em>Culture, Technology, Communication: Towards an Intercultural
Global Village</em>, Albany: SUNY Press, 1-50.</li>

<li>Ess, C. (2004), &ldquo;Computer-Mediated Communication and
Human-Computer Interaction,&rdquo; in L. Floridi (ed.), <em>The
Blackwell Guide to the Philosophy of Computing and Information</em>,
Oxford: Blackwell, 76-91.</li>

<li>Ess, C. (2005), &ldquo;Moral Imperatives for Life in an
Intercultural Global Village, &rdquo; in R. Cavalier (ed.), <em>The
Impact of the Internet on our Moral Lives</em>, Albany: SUNY Press,
161-193.</li>

<li>Ess, C. (2008), &ldquo;Culture and Global Networks: Hope for a
Global Ethics?&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 195-225.</li>

<li>Fairweather, B. (1998), &ldquo;No PAPA: Why Incomplete Codes of Ethics
are Worse than None at all,&rdquo; in G. Collste (ed.), <em>Ethics and
Information Technology</em>, New Delhi: New Academic Publishers.</li>

<li>Flanagan, M., D. Howe, and H. Nissenbaum (2008), &ldquo;Embodying
Value in Technology: Theory and Practice,&rdquo; in J. van den Hoven
and J. Weckert (eds.), <em>Information Technology and Moral
Philosophy</em>, Cambridge: Cambridge University Press, 322-53.</li>

<li>Floridi, L. (1999), &ldquo;Information Ethics: On the Theoretical
Foundations of Computer Ethics&rdquo;, <em>Ethics and Information
Technology</em>, 1(1): 37-56.</li>

<li>Floridi, L. (ed.) (2004), <em>The Blackwell Guide to the Philosophy
of Computing and Information</em>, Oxford: Blackwell.</li>

<li>Floridi, L. (2005b), &ldquo;Internet Ethics: The Constructionist
Values of Homo Poieticus,&rdquo; in R. Cavalier (ed.), <em>The Impact of the
Internet on our Moral Lives</em>, Albany: SUNY Press, 195-214.</li>

<li>Floridi, L. (2006a), &ldquo;Information Ethics: Its Nature and
Scope,&rdquo; <em>Computers and Society</em>, 36(3): 21-36.</li>

<li>Floridi, L. (2006b), &ldquo;Information Technologies and the
Tragedy of the Good Will,&rdquo; <em>Ethics and Information
Technology</em>, 8(4): 253-262.</li>

<li>Floridi, L. (2008), &ldquo;Information Ethics: Its Nature and
Scope,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 40-65.</li>

<li>Floridi, L. and J. Sanders (2004), &ldquo;The Foundationalist
Debate in Computer Ethics,&rdquo; in R. Spinello and H.  Tavani
(eds.), <em>Readings in CyberEthics</em>, 2nd edition, Sudbury, MA:
Jones and Bartlett, 81-95.</li>

<li>Fodor, J. and T. Bynum (1992), <em>What Is Computer Ethics?</em>
(a video program), Kingston, NY: Educational Media Resources,
Inc.</li>

<li>Forester, T. and P. Morrison (1990), <em>Computer Ethics:
Cautionary Tales and Ethical Dilemmas in Computing</em>, Cambridge,
MA: MIT Press.</li>

<li>Fried, C. (1984), &ldquo;Privacy,&rdquo; in F. Schoeman (ed.),
<em>Philosophical Dimensions of Privacy</em>, Cambridge: Cambridge
University Press.</li>

<li>Friedman, B. (ed.) (1997), <em>Human Values and the Design of
Computer Technology</em>, Cambridge: Cambridge University Press.</li>

<li>Friedman, B. and H. Nissenbaum (1996), &ldquo;Bias in Computer
Systems,&rdquo; <em>ACM Transactions on Information Systems</em>,
14(3): 330-347.</li>

<li>Gert, B. (1998), <em>Morality: Its Nature and Justification</em>, Oxford:
Oxford University Press.</li>

<li>Gert, B. (1999), &ldquo;Common Morality and
Computing,&rdquo; <em>Ethics and Information Technology</em>, 1(1):
57-64.</li>

<li>Goldman, A. (2008), &ldquo;The Social Epistemology of
Blogging,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 111-22.</li>

<li>Gordon, W. (2008), &ldquo;Moral Philosophy, Information Technology,
and Copyright: The Grokster Case,&rdquo; in J. van den Hoven and J.
Weckert (eds.), <em>Information Technology and Moral Philosophy</em>, Cambridge:
Cambridge University Press, 270-300.</li>

<li>Gorniak-Kocikowska, K. (1996), &ldquo;The Computer Revolution and
the Problem of Global Ethics,&rdquo; in T. Bynum and S.  Rogerson
(eds.), <em>Global Information Ethics</em>, Guildford, UK: Opragen
Publications, 177-90.</li>

<li>Gorniak-Kocikowska, K. (2005) &ldquo;From Computer Ethics to the
Ethics of Global ICT Society,&rdquo; in T. Bynum, G. Collste, and
S. Rogerson (eds.), <em>Proceedings of ETHICOMP2005</em> (CD-ROM),
Center for Computing and Social Responsibility, Link&ouml;pings
University.</li>

<li>Gorniak-Kocikowska, K. (2007), &ldquo;ICT, Globalization and the
Pursuit of Happiness: The Problem of Change,&rdquo; in <em>Proceedings of
ETHICOMP2007</em>, Tokyo: Meiji University Press.</li>

<li>Gotterbarn, D. (1991), &ldquo;Computer Ethics: Responsibility
Regained,&rdquo; <em>National Forum: The Phi Beta Kappa Journal</em>, 71:
26-31.</li>

<li>Gotterbarn, D. (2001), &ldquo;Informatics and Professional
Responsibility,&rdquo; <em>Science and Engineering Ethics</em>, 7(2):
221-30.</li>

<li>Gotterbarn, D. (2002) &ldquo;Reducing Software Failures: Addressing
the Ethical Risks of the Software Development Life Cycle,&rdquo; <em>Australian
Journal of Information Systems</em>, 9(2): 155-65.</li>

<li>Gotterbarn, D., K. Miller, and S. Rogerson (1997), &ldquo;Software
Engineering Code of Ethics,&rdquo; <em>Information Society</em>,
40(11): 110-118.</li>

<li>Gotterbarn, D. and K. Miller (2004), &ldquo;Computer Ethics in the
Undergraduate Curriculum: Case Studies and the Joint Software
Engineer's Code,&rdquo; <em>Journal of Computing Sciences in
Colleges</em>, 20(2): 156-167.</li>

<li>Gotterbarn, D. and S. Rogerson (2005), &ldquo;Responsible Risk
Analysis for Software Development: Creating the Software Development
Impact Statement,&rdquo; <em>Communications of the Association for
Information Systems</em>, 15(40): 730-50.</li>

<li>Grodzinsky, F. (1997), &ldquo;Computer Access for Students with
Disabilities,&rdquo; <em>SIGSCE Bulletin</em>, 29(1): 292-295;
[<a href="http://portal.acm.org/toc.cfm?id=268085&amp;coll=GUIDE&amp;dl=GUIDE&amp;type=issue&amp;idx=J688" target="other">Available online</a>].</li>

<li>Grodzinsky, F. (1999), &ldquo;The Practitioner from Within: Revisiting
the Virtues,&rdquo; <em>Computers and Society</em>, 29(2): 9-15.</li>

<li>Grodzinsky, F., K. Miller and M. Wolfe (2003), &ldquo;Ethical
Issues in Open Source Software,&rdquo; <em>Journal of Information,
Communication and Ethics in Society</em>, 1(4): 193-205.</li>

<li>Grodzinsky, F. and H. Tavani (2002), &ldquo;Ethical Reflections
on Cyberstalking,&rdquo; <em>Computers and Society</em>, 32(1): 22-32.</li>

<li>Grodzinsky, F. and H. Tavani (2004), &ldquo;Verizon vs. the RIAA:
Implications for Privacy and Democracy,&rdquo; in J. Herkert
(ed.), <em>Proceedings of ISTAS 2004: The International Symposium on
Technology and Society</em>, Los Alamitos, CA: IEEE Computer Society
Press.</li>

<li>Himma, K. (2003), &ldquo;The Relationship Between the Uniqueness of
Computer Ethics and its Independence as a Discipline in Applied
Ethics,&rdquo; <em>Ethics and Information Technology</em>, 5(4):
225-237.</li>

<li>Himma, K. (2004), &ldquo;The Moral Significance of the Interest in
Information: Reflections on a Fundamental Right to Information,&rdquo;
<em>Journal of Information, Communication, and Ethics in Society</em>,
2(4): 191-202.</li>

<li>Himma, K. (2007), &ldquo;Artificial Agency, Consciousness, and the
Criteria for Moral Agency: What Properties Must an Artificial Agent
Have to be a Moral Agent?&rdquo; in <em>Proceedings of
ETHICOMP2007</em>, Tokyo: Meiji University Press.</li>

<li>Himma, K. (2004), &ldquo;There's Something about Mary: The Moral
Value of Things qua Information Objects&rdquo;, <em>Ethics and Information
Technology</em>, 6(3): 145-159.</li>

<li>Himma, K. (2006), &ldquo;Hacking as Politically Motivated Civil
Disobedience: Is Hacktivism Morally Justified?&rdquo; in K. Himma
(ed.), <em>Readings in Internet Security: Hacking, Counterhacking, and
Society</em>, Sudbury, MA: Jones and Bartlett.</li>

<li>Huff. C., J. Fleming, and J. Cooper (1991), &ldquo;The Social Basis
of Gender Differences in Human-computer Interaction.&rdquo; in C. Martin
(ed.), <em>In Search of Gender-free Paradigms for Computer Science Education</em>,
Eugene, OR: ISTE Research Monographs,  19-32.</li>

<li>Huff, C. and T. Finholt (eds.) (1994), <em>Social Issues in Computing:
Putting Computers in Their Place</em>, New York: McGraw-Hill.</li>

<li>Huff, C. and D. Martin (1995), &ldquo;Computing Consequences: A
Framework for Teaching Ethical Computing,&rdquo; <em>Communications of
the ACM</em>, 38(12): 75-84.</li>

<li>Huff, C. (2002), &ldquo;Gender, Software Design, and Occupational
Equity,&rdquo; <em>SIGCSE Bulletin: Inroads</em>, 34: 112-115.</li>

<li>Huff, C. (2004), &ldquo;Unintentional Power in the Design of
Computing Systems.&rdquo; in T. Bynum and S. Rogerson
(eds.), <em>Computer Ethics and Professional Responsibility</em>,
Oxford: Blackwell.</li>

<li>Huff, C., D. Johnson, and K. Miller (2003), &ldquo;Virtual Harms
and Real Responsibility,&rdquo; <em>Technology and Society
Magazine</em> (IEEE), 22(2): 12-19.</li>

<li>Introna, L. (1997), &ldquo;Privacy and the Computer: Why We Need
Privacy in the Information Society,&rdquo; <em>Metaphilosophy</em>, 28(3):
259-275.</li>

<li>Introna, L. (2002), &ldquo;On the (Im)Possibility of Ethics in a
Mediated World,&rdquo; <em>Information and Organization</em>, 12(2):
71-84.</li>

<li>Introna, L. (2005a), &ldquo;Disclosive Ethics and Information
Technology: Disclosing Facial Recognition Systems,&rdquo; <em>Ethics and
Information Technology</em>, 7(2): 75-86.</li>

<li>Introna, L. (2005b) &ldquo;Phenomenological Approaches to Ethics
and Information Technology,&rdquo; The Stanford Encyclopedia of
Philosophy  (Fall 2005 Edition), Edward N. Zalta (ed.), URL =
 &lt;http://plato.stanford.edu/archives/fall2005/entries/ethics-it-phenomenology/&gt;.</li>

 
<li>Introna, L. and H. Nissenbaum (2000), &ldquo;Shaping the Web: Why
the Politics of Search Engines Matters,&rdquo; <em>The Information
Society</em>, 16(3): 1-17.</li>

<li>Introna, L. and N. Pouloudi (2001), &ldquo;Privacy in the
Information Age: Stakeholders, Interests and Values.&rdquo; in J. Sheth
(ed.), <em>Internet Marketing</em>, Fort Worth, TX: Harcourt College Publishers,
373-388.</li>

<li>Johnson, D. (1985), <em>Computer Ethics</em>, First Edition,
Englewood Cliffs, NJ: Prentice-Hall; Second Edition, Englewood Cliffs,
NJ: Prentice-Hall, 1994; Third Edition Upper Saddle River, NJ:
Prentice-Hall, 2001.</li>

<li>Johnson, D. (1997a), &ldquo;Ethics
Online,&rdquo; <em>Communications of the ACM</em>, 40(1): 60-65.</li>

<li>Johnson, D. (1997b), &ldquo;Is the Global Information
Infrastructure a Democratic Technology?&rdquo; <em>Computers and
Society</em>, 27(4): 20-26.</li>

<li>Johnson, D. (2004), &ldquo;Computer Ethics,&rdquo; in L. Floridi
(ed.), <em>The Blackwell Guide to the Philosophy of Computing and
Information</em>, Oxford: Blackwell, 65-75.</li>

<li>Johnson, D. and H. Nissenbaum (eds.) (1995), <em>Computing, Ethics
&amp; Social Values</em>, Englewood Cliffs, NJ: Prentice Hall.</li>

<li>Johnson, D. and T. Powers (2008), &ldquo;Computers as Surrogate
Agents,&rdquo; in J. van den Hoven and J. Weckert,
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 251-69.</li>

<li>Kocikowski, A. (1996), &ldquo;Geography and Computer Ethics: An
Eastern European Perspective,&rdquo; in T. Bynum and S.  Rogerson
(eds.), <em>Science and Engineering Ethics</em> (Special Issue: Global
Information Ethics), 2(2): 201-10.</li>

<li>Maner, W. (1980), <em>Starter Kit in Computer Ethics</em>, Hyde
Park, NY: Helvetia Press and the National Information and Resource
Center for Teaching Philosophy.</li>

<li>Maner, W. (1996), &ldquo;Unique Ethical Problems in Information
Technology,&rdquo; in T. Bynum and S. Rogerson (eds.),
<em>Science and Engineering Ethics</em> (Special Issue: Global
Information Ethics), 2(2): 137-154.</li>

<li>Martin, C. and D. Martin (1990), &ldquo;Professional Codes of
Conduct and Computer Ethics Education,&rdquo; <em>Social Science Computer
Review</em>, 8(1): 96-108.</li>

<li>Martin, C., C. Huff, D. Gotterbarn, K. Miller, <em>et
al</em>. (1996), &ldquo;A Framework for Implementing and Teaching the
Social and Ethical Impact of Computing,&rdquo; <em>Education and
Information Technologies</em>, 1(2): 101-122.</li>

<li>Martin, C., C. Huff, D. Gotterbarn, and K. Miller (1996),
&ldquo;Implementing a Tenth Strand in the Computer Science
Curriculum&rdquo; (Second Report of the Impact CS Steering
Committee), <em>Communications of the ACM</em>, 39(12): 75-84.</li>

<li>Marx, G. (2001), &ldquo;Identity and Anonymity: Some Conceptual
Distinctions and Issues for Research,&rdquo; in J. Caplan and
J. Torpey (eds.), <em>Documenting Individual Identity</em>, Princeton:
Princeton University Press.</li>

<li>Mather, K. (2005), &ldquo;The Theoretical Foundation of Computer
Ethics: Stewardship of the Information Environment,&rdquo;
in <em>Contemporary Issues in Governance</em> (Proceedings of GovNet
Annual Conference, Melbourne, Australia, 28-30 November, 2005),
Melbourne: Monash University.</li>

<li>Matthews, S. (2008), &ldquo;Identity and Information
Technology.&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 142-60.</li>

<li>Miller, A. (1971), <em>The Assault on Privacy: Computers, Data
Banks, and Dossiers</em>, Ann Arbor: University of Michigan
Press.</li>

<li>Miller, K. (2005), &ldquo;Web standards: Why So Many Stray from the
Narrow Path,&rdquo; <em>Science and Engineering Ethics</em>, 11(3):
477-479.</li>

<li>Miller, K. and D. Larson (2005a), &ldquo;Agile Methods and Computer
Ethics: Raising the Level of Discourse about Technological Choices,&rdquo;
<em>IEEE Technology and Society</em>, 24(4): 36-43.</li>

<li>Miller, K. and D. Larson (2005b), &ldquo;Angels and Artifacts: Moral
Agents in the Age of Computers and Networks,&rdquo; <em>Journal of Information,
Communication &amp; Ethics in Society</em>, 3(3): 151-157.</li>

<li>Miller, S. (2008), &ldquo;Collective Responsibility and
Information and Communication Technology.&rdquo; in J. van den Hoven
and J> Weckert (eds.), <em>Information Technology and Moral
Philosophy</em>, Cambridge: Cambridge University Press, 226-50.</li>

<li>Moor, J.. (1979), &ldquo;Are there Decisions Computers Should Never
Make?&rdquo; <em>Nature and System</em>, 1: 217-29.</li>

<li>Moor, J. (1985) &ldquo;What Is Computer
Ethics?&rdquo; <em>Metaphilosophy</em>, 16(4): 266-75.</li>

<li>Moor, J. (1996), &ldquo;Reason, Relativity and Responsibility in
Computer Ethics,&rdquo; in <em>Computers and Society</em>, 28(1)
(1998): 14-21; originally a keynote address at ETHICOMP96 in Madrid,
Spain, 1996.</li>

<li>Moor, J. (1997), &ldquo;Towards a Theory of Privacy in the
Information Age,&rdquo; <em>Computers and Society</em>, 27(3): 27-32.</li>

<li>Moor, J. (1999), &ldquo;Just Consequentialism and Computing,&rdquo;
<em>Ethics and Information Technology</em>, 1(1): 65-69.</li>

<li>Moor, J. (2001), &ldquo;The Future of Computer Ethics: You Ain't
Seen Nothin' Yet,&rdquo; <em>Ethics and Information Technology</em>, 3(2):
89-91.</li>

<li>Moor, J. 2005), &ldquo;Should We Let Computers Get under Our
Skin?&rdquo; in R. Cavalier (ed.), <em>The Impact of the Internet on
our Moral Lives</em>, Albany: SUNY Press, 121-138.</li>

<li>Moor, J. (2006), &ldquo;The Nature, Importance, and Difficulty of
Machine Ethics,&rdquo; <em>IEEE Intelligent Systems</em>, 21(4): 18-21.</li>

<li>Moor, J. (2008) &ldquo;Why We Need Better Ethics for Emerging
Technologies,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 26-39.</li>

<li>Nissenbaum, H. (1995), &ldquo;Should I Copy My Neighbor's
Software?&rdquo; in D. Johnson and H. Nissenbaum (eds), <em>Computers,
Ethics, and Social Responsibility</em>, Englewood Cliffs, NJ: Prentice Hall.</li>

<li>Nissenbaum, H. (1997), &ldquo;Can We Protect Privacy in Public?&rdquo; in
<em>Proceedings of Computer Ethics&mdash;Philosophical Enquiry 97</em>
(CEPE97), Rotterdam: Erasmus University Press, 191-204; reprinted
Nissenbaum 1998a.</li>

<li>Nissenbaum, H. (1998a), &ldquo;Protecting Privacy in an
Information Age: The Problem of Privacy in Public,&rdquo; <em>Law and
Philosophy</em>, 17: 559-596.</li>

<li>Nissenbaum, H. (1998b), &ldquo;Values in the Design of Computer
Systems,&rdquo; <em>Computers in Society</em>, 1998: 38-39.</li>

<li>Nissenbaum, H. (1999), &ldquo;The Meaning of Anonymity in an
Information Age,&rdquo; <em>The Information Society</em>, 15:
141-144.</li>

<li>Nissenbaum, H. (2005a), &ldquo;Hackers and the Contested Ontology
of Cyberspace,&rdquo; in R. Cavalier (ed.), <em>The Impact of the
Internet on our Moral Lives</em>, Albany: SUNY Press, 139-160.</li>

<li>Nissenbaum, H. (2005b), &ldquo;Where Computer Security Meets National
Security,&rdquo; <em>Ethics and Information Technology</em>, 7(2):
61-73.</li>

<li>Parker, D. (1968), &ldquo;Rules of Ethics in Information Processing,&rdquo;
<em>Communications of the ACM</em>, 11: 198-201.</li>

<li>Parker, D. (1979), <em>Ethical Conflicts in Computer Science and
Technology</em>. Arlington, VA: AFIPS Press.</li>

<li>Parker, D., S. Swope and B. Baker (1990), <em>Ethical Conflicts in
Information &amp; Computer Science, Technology &amp; Business</em>,
Wellelsey, MA: QED Information Sciences.</li>

<li>Pecorino, P. and W. Maner (1985), &ldquo;A Proposal for a Course
on Computer Ethics,&rdquo; <em>Metaphilosophy</em>, 16(4):
327-337.</li>

<li>Perrolle, J. (1987), <em>Computers and Social Change: Information,
Property, and Power</em>, Belmont, CA: Wadsworth.</li>

<li>Pettit, P. (2008), &ldquo;Trust, Reliance, and the
Internet,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 161-74.</li>

<li>Rogerson, S. (1996), &ldquo;The Ethics of Computing: The First and
Second Generations,&rdquo; <em>The UK Business Ethics Network
News</em>, 6: 1-4.</li>

<li>Rogerson, S. (1998), &ldquo;Computer and Information
Ethics,&rdquo; in R. Chadwick (ed.), <em>Encylopedia of Applied
Ethics</em>, San Diego, CA: Academic Press, 563-570.</li>

<li>Rogerson, S. (2004), &ldquo;The Ethics of Software Development
Project Management,&rdquo; in T. Bynum and S. Rogerson
(eds.), <em>Computer Ethics and Professional Responsibility</em>,
Oxford: Blackwell, 119-128.</li>

<li>Rogerson, S. and T. Bynum (1995), &ldquo;Cyberspace: The Ethical
Frontier,&rdquo; <em>The Times Higher Education Supplement</em> (The
London Times), No. 1179, June, 9, 1995, iv.</li>

<li>Rogerson, S., B. Fairweather, and M. Prior (2002), &ldquo;The Ethical
Attitudes of Information Systems Professionals: Outcomes of an Initial
Survey,&rdquo; <em>Telematics and Informatics</em>, 19: 21-36.</li>

<li>Rogerson, S. and D. Gotterbarn (1998), &ldquo;The Ethics of
Software Project Management,&rdquo; in G. Collste (ed.), <em>Ethics
and Information Technology</em>, New Delhi: New Academic Publishers,
137-154.</li>

<li>Sojka, J. (1996), &ldquo;Business Ethics and Computer Ethics: The View
from Poland,&rdquo; in T. Bynum and S. Rogerson (eds.), <em>Global
Information Ethics</em>, Guildford, UK: Opragen Publications, 191-200.</li>

<li>Spafford, E., K. Heaphy, and D. Ferbrache (eds.)
(1989), <em>Computer Viruses: Dealing with Electronic Vandalism and
Programmed Threats</em>, Arlington, VA: ADAPSO (now ITAA).</li>

<li>Spafford, E. (1992), &ldquo;Are Computer Hacker Break-Ins Ethical?&rdquo;
<em>Journal of Systems and Software</em>, 17: 41-47.</li>

<li>Spinello, R. (1997), <em>Case Studies in Information and Computer
Ethics</em>, Upper Saddle River, NJ: Prentice-Hall.</li>

<li>Spinello, R. (2000), <em>CyberEthics: Morality and Law in
Cyberspace</em>, Sudbury, MA: Jones and Bartlett.</li>

<li>Spinello, R. and H. Tavani (2001a), &ldquo;The Internet, Ethical
Values, and Conceptual Frameworks: An Introduction to
Cyberethics,&rdquo; <em>Computers and Society</em>, 31(2): 5-7.</li>

<li>Spinello, R, and H. Tavani (eds.) (2001b),
<em>Readings in CyberEthics</em>, Sudbury, MA: Jones and Bartlett;
Second Edition, 2004.</li>

<li>Spinello, R. and H.. Tavani (eds.)  (2005),
<em>Intellectual Property Rights in a Networked World: Theory and
Practice</em>, Hershey, PA: Idea Group/Information Science
Publishing.</li>

<li>Stahl, B. (2004a), &ldquo;Information, Ethics and Computers: The
Problem of Autonomous Moral Agents,&rdquo; <em>Minds and Machines</em>, 14:
67-83.</li>

<li>Stahl, B. (2004b), <em>Responsible Management of Information
Systems</em>, Hershey, PA: Idea Group/Information Science
Publishing.</li>

<li>Stahl, B. (2005), &ldquo;The Ethical Problem of Framing
E-Government in Terms of E-Commerce,&rdquo; <em>Electronic Journal of
E-Government</em>, 3(2): 77-86.</li>

<li>Stahl, B. (2006), &ldquo;Responsible Computers? A Case for
Ascribing Quasi-responsibility to Computers Independent of Personhood
or Agency,&rdquo; <em>Ethics and Information Technology</em>, 8(4):
205-213.</li>

<li>Sunstein, C. (2008), &ldquo;Democracy and the Internet,&rdquo; in
J. van den Hoven and J. Weckert (eds.), <em>Information Technology and
Moral Philosophy</em>, Cambridge: Cambridge University Press,
93-110.</li>

<li>Tavani, H. (ed.) (1996), <em>Computing, Ethics, and Social
Responsibility: A Bibliography</em>, Palo Alto, CA: Computer
Professionals for Social Responsibility Press.</li>

<li>Tavani, H. (1999a), &ldquo;Privacy and the Internet,&rdquo;
<em>Proceedings of the Fourth Annual Ethics and Technology
Conference</em>, Chestnut Hill, MA: Boston College Press, 114-25.</li>

<li>Tavani, H. (1999b), &ldquo;Privacy On-Line,&rdquo; <em>Computers
and Society</em>, 29(4): 11-19.</li>

<li>Tavani, H. (2002), &ldquo;The Uniqueness Debate in Computer
Ethics: What Exactly is at Issue and Why Does it Matter?&rdquo; <em>Ethics and
Information Technology</em>, 4(1): 37-54.</li>

<li>Tavani, H. (2004), <em>Ethics and Technology: Ethical Issues in an
Age of Information and Communication Technology</em>, Hoboken, NJ:
John Wiley and Sons; Second Edition, 2007.</li>

<li>Tavani, H. (2005), &ldquo;The Impact of the Internet on our Moral
Condition: Do We Need a New Framework of Ethics?&rdquo; in R. Cavalier
(ed.), <em>The Impact of the Internet on our Moral Lives</em>, Albany:
SUNY Press, 215-237.</li>

<li>Tavani, H. (2006), <em>Ethics, Computing, and Genomics</em>,
Sudbury, MA: Jones and Bartlett.</li>

<li>Tavani, H. and J. Moor (2001), &ldquo;Privacy Protection, Control
of Information, and Privacy-Enhancing
Technologies,&rdquo; <em>Computers and Society</em>, 31(1): 6-11.</li>

<li>Turkle, S.  (1984), <em>The Second Self: Computers and the Human
Spirit</em>, New York: Simon &amp; Schuster.</li>

<li>Turner, A.J. (1991), &ldquo;Summary of the ACM/IEEE-CS Joint
Curriculum Task Force Report: Computing Curricula, 1991,&rdquo;
<em>Communications of the ACM</em>, 34(6): 69-84.</li>

<li>Turner, E. (2006), &ldquo;Teaching Gender-Inclusive Computer
Ethics, &rdquo; in I. Trauth (ed.), <em>Encyclopedia of Gender and
Information Technology: Exploring the Contributions, Challenges,
Issues and Experiences of Women in Information Technology</em>,
Hershey,  PA: Idea Group/Information Science Publishing, 1142-1147.</li>

<li>van den Hoven, J. (1997a), &ldquo;Computer Ethics and Moral
Methodology,&rdquo; <em>Metaphilosophy</em>, 28(3): 234-48.</li>

<li>van den Hoven, J. (1997b), &ldquo;Privacy and the Varieties of
Informational Wrongdoing,&rdquo; <em>Computers and Society</em>,
27(3): 33-37.</li>

<li>van den Hoven, J. (1998), &ldquo;Ethics, Social Epistemics,
Electronic Communication and Scientific Research,&rdquo; <em>European
Review</em>, 7(3): 341-349. </li>

<li>van den Hoven, J. (2008a), &ldquo;Information Technology, Privacy,
and the Protection of Personal Data,&rdquo; in J. van den Hoven and
J. Weckert (eds.), <em>Information Technology and Moral
Philosophy</em>, Cambridge: Cambridge University Press, 301-321.</li>

<li>van den Hoven, J. and E. Rooksby (2008), &ldquo;Distributive
Justice and the Value of Information: A (Broadly) Rawlsian
Approach,&rdquo; in J. van den Hoven and J. Weckert
(eds.), <em>Information Technology and Moral Philosophy</em>,
Cambridge: Cambridge University Press, 376-96.</li>

<li>van den Hoven, J. and J. Weckert (2008), <em>Information
Technology and Moral Philosophy</em>, Cambridge: Cambridge University
Press.</li>

<li>Volkman, R. (2003), &ldquo;Privacy as Life, Liberty, Property,&rdquo;
<em>Ethics and Information Technology</em>, 5(4): 199-210.</li>

<li>Volkman, R. (2005), &ldquo;Dynamic Traditions: Why Globalization
Does Not Mean Homogenization,&rdquo; in <em>Proceedings of
ETHICOMP2005</em> (CD-ROM), Center for Computing and Social
Responsibility, Link&ouml;pings University.</li>

<li>Volkman, R. (2007), &ldquo;The Good Computer Professional Does Not
Cheat at Cards,&rdquo; in <em>Proceedings of ETHICOMP2007</em>, Tokyo:
Meiji University Press.</li>

<li>Weckert, J. (2002), &ldquo;Lilliputian Computer Ethics,&rdquo;
<em>Metaphilosophy</em>, 33(3): 366-375.</li>

<li>Weckert, J. (2005), &ldquo;Trust in Cyberspace,&rdquo; in
R. Cavalier (ed.), <em>The Impact of the Internet on our Moral
Lives</em>, Albany: SUNY Press, 95-117.</li>

<li>Weckert, J. and D. Adeney (1997), <em>Computer and Information
Ethics</em>, Westport, CT: Greenwood Press.</li>

<li>Weizenbaum, J.  (1976), <em>Computer Power and Human Reason: From
Judgment to Calculation</em>, San Francisco, CA: Freeman.</li>

<li>Westin, A. (1967), <em>Privacy and Freedom</em>, New York:
Atheneum.</li>

<li>Wiener, N. (1948), <em>Cybernetics: or Control and Communication
in the Animal and the Machine</em>, New York: Technology Press/John
Wiley &amp; Sons.</li>

<li>Wiener, N. (1950), <em>The Human Use of Human Beings: Cybernetics
and Society</em>, Boston: Houghton Mifflin; Second Edition Revised, New
York, NY: Doubleday Anchor 1954.</li>

<li>Wiener, N. (1964), <em>God &amp; Golem, Inc.: A Comment on Certain
Points Where Cybernetics Impinges on Religion</em>, Cambridge, MA: MIT
Press.</li>

</ul>

<h2><a name="AcaToo">Academic Tools</a></h2>

<blockquote>
<table>
<tr>
<td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="http://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=ethics-computer" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/ethics-computer/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://inpho.cogs.indiana.edu/entity?sep=ethics-computer&amp;redirect=True" target="other">Look up this entry topic</a>
 at the <a href="https://inpho.cogs.indiana.edu/" target="other">Indiana Philosophy Ontology Project</a>
 (InPhO).</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/ethics-computer/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>


<h2><a name="Oth">Other Internet Resources</a></h2>


<h3><a name="PapBoo">Papers and Books</a></h3>

<ul>

<li>Bynum, T., W. Maner, and J. Fodor (eds.) (1993),
 <a href="http://www.southernct.edu/organizations/rccs/oldsite/resources/teaching/teaching_mono/teaching_comp_eth_contents.html" target="other"><em>Teaching Computer Ethics</em></a>, 
 New Haven: Research Center on Computing &amp; Society.</li>

<li>Bynum, T. (1993), 
 &ldquo;<a href="http://www.southernct.edu/organizations/rccs/oldsite/resources/teaching/teaching_mono/bynum/bynum_human_values.html" target="other">Computer Ethics in the Computer Science Curriculum</a>,&rdquo; 
 in Bynum, Maner, and Fodor (eds.) 1993. </li>

<li><a href="http://www.progfree.org/Patents/against-software-patents.html" target="other">Against Software Patents</a>,
 The League for Programming Freedom (1991).</li>

<li><a href="http://www.gnu.org/philosophy/shouldbefree.html" target="other">Why Software Should Be Free</a>,
 paper by Richard Stallman (1991).</li>

</ul>


<h3><a name="JouWebSit">Journals and Web Sites</a></h3>

<ul>

<li><a href="http://www.emeraldinsight.com/info/journals/jices/jices.jsp" target="other"><em>Journal of
Information, Communication &amp; Ethics in Society</em></a></li>

<li><a href="http://www.ccsr.cse.dmu.ac.uk/journal/" target="other"><em>The ETHICOMP Journal</em></a></li>

<li><a href="http://www.acm.org/sigcas/" target="other">ACM SIGCAS</a>,
 Special Interest Group on Computers and Society,
Association for Computing Machinery</li>

<li><a href="http://www.ccsr.cse.dmu.ac.uk/" target="other">Centre for Computing and Social Responsibility</a>, 
 De Montfort University, UK</li>

<!-- LINK CHECKER COMMENTED OUT (Sun Apr 17 07:01:42 2011)
<li><a href="http://cyberethics.cbi.msstate.edu/biblio/"  target="other">Computer Ethics Bibliography</a>,
 by Herman Tavani (Rivier College)</li>

 LINK CHECKER -->
<li><a href="http://www.emr.org/linksUCE.html" target="other">Information on Computer Ethics</a>,
  Educational Media Resources, Inc.</li>

<!-- LINK CHECKER COMMENTED OUT (Sun Jul  1 05:43:01 2012)
<li><a href="http://www.eff.org/" target="other">Electronic Frontier Foundation</a></li>

 LINK CHECKER -->
<li><a href="http://www.epic.org/" target="other">Electronic Privacy Information Center</a></li>

<li><a href="http://www.computerethics.org/" target="other">Research  Center on Computing &amp; Society</a>,
 Southern Connecticut State University</li>

<li><a href="http://seeri.etsu.edu/" target="other">Software  Engineering Ethics Research Institute</a>,
 East Tennessee State University)</li>

</ul>

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../privacy/">privacy</a> |
 <a href="../property/">property and ownership</a>

</p>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<div id="foot">
<span style="font-size: 11pt;"> <a href="../../info.html#c">Copyright &copy; 2008</a> by
</span>
<br />
<a href="http://home.southernct.edu/~bynumt2/" target="other">Terrell Bynum</a>
&lt;<a href="m&#97;ilto:bynumt2&#37;40southernct&#37;2eedu"><em>bynumt2<abbr title=" at ">&#64;</abbr>southernct<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
</div><!-- end #foot -->
</div><!-- end #content -->
</body>
</html>
